<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>MarkDown è¯­æ³•</title>
    <url>/blog/2021/11/28/MarkDown%20introduce/</url>
    <content><![CDATA[<h1 id="MarkDown-è¯­æ³•æ€»ç»“"><a href="#MarkDown-è¯­æ³•æ€»ç»“" class="headerlink" title="MarkDown è¯­æ³•æ€»ç»“"></a>MarkDown è¯­æ³•æ€»ç»“</h1><h2 id="æ¢è¡Œ"><a href="#æ¢è¡Œ" class="headerlink" title="æ¢è¡Œ"></a>æ¢è¡Œ</h2><ul>
<li><strong>markdown</strong> ä¸­å¯ä»¥ä½¿ç”¨â€œç©ºä¸€è¡Œâ€æ¥å®ç°æ¢è¡Œ</li>
</ul>
<figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">Keras æœ‰ä¸¤ä¸ªé‡è¦çš„æ¦‚å¿µï¼š </span><br><span class="line"></span><br><span class="line">æ¨¡å‹ï¼ˆModelï¼‰:</span><br><span class="line"></span><br><span class="line">å±‚ï¼ˆLayerï¼‰ :</span><br></pre></td></tr></table></figure>

<ul>
<li>å¯ä»¥ä½¿ç”¨ HTML &lt;br&gt; æ¢è¡Œ</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Keras æœ‰ä¸¤ä¸ªé‡è¦çš„æ¦‚å¿µï¼š&lt;br&gt;</span><br><span class="line">æ¨¡å‹ï¼ˆModelï¼‰: &lt;br&gt;</span><br><span class="line">å±‚ï¼ˆLayerï¼‰:</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<span id="more"></span>

<h2 id="å¹¶åˆ—æ’å…¥å¤šå¹…å›¾ç‰‡"><a href="#å¹¶åˆ—æ’å…¥å¤šå¹…å›¾ç‰‡" class="headerlink" title="å¹¶åˆ—æ’å…¥å¤šå¹…å›¾ç‰‡"></a>å¹¶åˆ—æ’å…¥å¤šå¹…å›¾ç‰‡</h2><figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">align</span>=<span class="string">&quot;center&quot;</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">img</span> <span class="attr">src</span>=<span class="string">&quot;001.png&quot;</span> <span class="attr">height</span>=<span class="string">&quot;120&quot;</span> <span class="attr">width</span>=<span class="string">&quot;188&quot;</span> &gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">img</span> <span class="attr">src</span>=<span class="string">&quot;012.png&quot;</span> <span class="attr">height</span>=<span class="string">&quot;120&quot;</span> <span class="attr">width</span>=<span class="string">&quot;188&quot;</span> &gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">img</span> <span class="attr">src</span>=<span class="string">&quot;032.png&quot;</span> <span class="attr">height</span>=<span class="string">&quot;120&quot;</span> <span class="attr">width</span>=<span class="string">&quot;188&quot;</span> &gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h2 id="å­—ä½“é¢œè‰²"><a href="#å­—ä½“é¢œè‰²" class="headerlink" title="å­—ä½“é¢œè‰²"></a>å­—ä½“é¢œè‰²</h2><p>å­—ä½“é¢œè‰²ï¼š<font color=Blue>Test</font></p>
<p> <code>&lt;font color=Blue&gt;Test&lt;/font&gt;</code></p>
<p>èƒŒæ™¯é¢œè‰²ï¼š<font style=background:red>Test</font></p>
<p><code>&lt;font style=background:red&gt;Test&lt;/font&gt;</code></p>
<h2 id="æ ‡é¢˜"><a href="#æ ‡é¢˜" class="headerlink" title="æ ‡é¢˜"></a>æ ‡é¢˜</h2><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line"><span class="section">#ä¸€çº§æ ‡é¢˜</span></span><br><span class="line"><span class="section">##äºŒçº§æ ‡é¢˜</span></span><br><span class="line"><span class="section">###ä¸‰çº§æ ‡é¢˜</span></span><br></pre></td></tr></table></figure>

<h2 id="åˆ—è¡¨"><a href="#åˆ—è¡¨" class="headerlink" title="åˆ—è¡¨"></a>åˆ—è¡¨</h2><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">æ— åºåˆ—è¡¨ï¼š</span><br><span class="line"><span class="bullet">-</span> åˆ—è¡¨1</span><br><span class="line"><span class="bullet">-</span> åˆ—è¡¨2</span><br><span class="line"><span class="code">	a å­åˆ—è¡¨1</span></span><br><span class="line"><span class="code">	b å­åˆ—è¡¨2</span></span><br><span class="line"><span class="code"></span></span><br><span class="line">æœ‰åºåˆ—è¡¨ï¼š</span><br><span class="line"><span class="bullet">1.</span> åˆ—è¡¨1</span><br><span class="line"><span class="bullet">2.</span> åˆ—è¡¨2</span><br></pre></td></tr></table></figure>

<h2 id="æ¨ªçº¿"><a href="#æ¨ªçº¿" class="headerlink" title="æ¨ªçº¿"></a>æ¨ªçº¿</h2><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">---</span><br><span class="line"></span><br><span class="line"><span class="strong">**<span class="emphasis">*</span></span></span><br></pre></td></tr></table></figure>

<h2 id="é“¾æ¥"><a href="#é“¾æ¥" class="headerlink" title="é“¾æ¥"></a>é“¾æ¥</h2><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">[<span class="string">ç½‘ç«™åå­—</span>](<span class="link">url</span>)</span><br></pre></td></tr></table></figure>

<h2 id="æ’å…¥å›¾ç‰‡"><a href="#æ’å…¥å›¾ç‰‡" class="headerlink" title="æ’å…¥å›¾ç‰‡"></a>æ’å…¥å›¾ç‰‡</h2><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">![<span class="string">å›¾ç‰‡åå­—</span>](<span class="link">url</span>)</span><br></pre></td></tr></table></figure>

<h2 id="å­—ä½“æ ¼å¼"><a href="#å­—ä½“æ ¼å¼" class="headerlink" title="å­—ä½“æ ¼å¼"></a>å­—ä½“æ ¼å¼</h2><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">ç²—ä½“ï¼š</span><br><span class="line"><span class="strong">**ç²—ä½“**</span></span><br><span class="line">æ–œä½“ï¼š</span><br><span class="line"><span class="emphasis">*ç²—ä½“*</span></span><br></pre></td></tr></table></figure>

<h2 id="ä»£ç å—"><a href="#ä»£ç å—" class="headerlink" title="ä»£ç å—"></a>ä»£ç å—</h2><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line"><span class="code">`hello, world!`</span></span><br><span class="line"></span><br><span class="line"><span class="code">```</span></span><br><span class="line"><span class="code">#include &lt;iostream&gt;</span></span><br><span class="line"><span class="code">using namespace std;</span></span><br><span class="line"><span class="code"></span></span><br><span class="line"><span class="code">int mian()&#123;</span></span><br><span class="line"><span class="code">    printf(&quot;hello, world!\n&quot;);</span></span><br><span class="line"><span class="code">    return 0;</span></span><br><span class="line"><span class="code">&#125;</span></span><br><span class="line"><span class="code">```</span></span><br></pre></td></tr></table></figure>

<h2 id="å¼•ç”¨"><a href="#å¼•ç”¨" class="headerlink" title="å¼•ç”¨"></a>å¼•ç”¨</h2><blockquote>
<p>å¼•ç”¨æ•ˆæœï¼</p>
</blockquote>
<figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">&gt;å¼•ç”¨æ•ˆæœï¼</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>MarkDown</category>
      </categories>
      <tags>
        <tag>MarkDown</tag>
      </tags>
  </entry>
  <entry>
    <title>Hello World</title>
    <url>/blog/2021/12/01/hello-world/</url>
    <content><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p>
<span id="more"></span>

<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>
]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title>project_architecture</title>
    <url>/blog/2021/12/07/project-architecture/</url>
    <content><![CDATA[<h1 id="DL-é¡¹ç›®çš„ç»„ç»‡æ¶æ„"><a href="#DL-é¡¹ç›®çš„ç»„ç»‡æ¶æ„" class="headerlink" title="DL é¡¹ç›®çš„ç»„ç»‡æ¶æ„"></a>DL é¡¹ç›®çš„ç»„ç»‡æ¶æ„</h1><span id="more"></span>

<p>é¡¹ç›®ç»“æ„å¦‚ä¸‹ï¼š</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># å»ºè®®ä½¿ç”¨æ–‡ä»¶å¤¹ï¼Œå¦‚æœæ–‡ä»¶å°‘çš„è¯ï¼Œå•ä¸ªæ–‡ä»¶ä¹Ÿæ˜¯å¯ä»¥çš„</span></span><br><span class="line">ProjectDir:</span><br><span class="line">- dataDir</span><br><span class="line">	-- datafile (Cifar10)</span><br><span class="line">- modelsDir <span class="keyword">or</span> model.py  <span class="comment"># å­˜æ”¾æ¨¡å‹æ–‡ä»¶</span></span><br><span class="line">	-- __init__.py (ç©ºæ–‡ä»¶å³å¯)</span><br><span class="line">	-- VGG18.py</span><br><span class="line">	-- resnet18.py</span><br><span class="line">	-- resnet50.py</span><br><span class="line">- utilsDir <span class="keyword">or</span> utils.py  <span class="comment"># å­˜æ”¾ä¸€äº›å·¥å…·æ–‡ä»¶</span></span><br><span class="line">	-- __init__.py</span><br><span class="line">	-- plots.py</span><br><span class="line">	-- loss.py</span><br><span class="line">	-- dataset.py</span><br><span class="line">	-- download.py</span><br><span class="line">- train.py (è¦åŒ…å«validationçš„åŠŸèƒ½)  <span class="comment"># è®­ç»ƒæ–‡ä»¶</span></span><br><span class="line">- test.py <span class="keyword">or</span> <span class="built_in">eval</span>.py  <span class="comment"># æµ‹è¯•æ–‡ä»¶</span></span><br><span class="line">- README.md  <span class="comment"># é¡¹ç›®ä»‹ç»æ–‡ä»¶</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">...... ä¸‹é¢è¿™äº›è¿˜ä¸å¤ªæ‡‚</span><br><span class="line">- detect.py</span><br><span class="line">- export.py</span><br><span class="line"></span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>Project Architecture</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>architecture</tag>
      </tags>
  </entry>
  <entry>
    <title>pip usage</title>
    <url>/blog/2021/12/11/pip-usage/pip-usage/</url>
    <content><![CDATA[<h1 id="Pip-Usage"><a href="#Pip-Usage" class="headerlink" title="Pip Usage"></a>Pip Usage</h1><h2 id="pip-åŸºæœ¬è¯­æ³•ğŸ˜‰"><a href="#pip-åŸºæœ¬è¯­æ³•ğŸ˜‰" class="headerlink" title="pip åŸºæœ¬è¯­æ³•ğŸ˜‰"></a>pip åŸºæœ¬è¯­æ³•ğŸ˜‰</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">pip install SomePackage            # latest version</span><br><span class="line">pip install SomePackage==1.0.4     # specific version</span><br><span class="line">pip install &#x27;SomePackage&gt;=1.0.4&#x27;   # minimum version</span><br></pre></td></tr></table></figure>

<span id="more"></span>

<h2 id="pip-é«˜çº§ç”¨æ³•ğŸ‘"><a href="#pip-é«˜çº§ç”¨æ³•ğŸ‘" class="headerlink" title="pip é«˜çº§ç”¨æ³•ğŸ‘"></a>pip é«˜çº§ç”¨æ³•ğŸ‘</h2><p>ç¼–å†™ package ç‰ˆæœ¬æ–‡ä»¶ <code>requirements.txt</code> (â—â€™â—¡â€™â—)</p>
<h3 id="å½“å‰å·²è£…åº“-list"><a href="#å½“å‰å·²è£…åº“-list" class="headerlink" title="å½“å‰å·²è£…åº“ list"></a>å½“å‰å·²è£…åº“ list</h3><p><code>pip freeze</code> å¯ä»¥å®ç°ï¼šè·å¾—é¡¹ç›®è¿è¡Œæ—¶ï¼Œæ‰€éœ€å®‰è£…åº“çš„å›ºå®šç‰ˆæœ¬</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">pip freeze &gt; requirements.txt</span><br></pre></td></tr></table></figure>

<p>è¿è¡Œè¯¥è¯­å¥åï¼Œåœ¨é¡¹ç›®ç›®å½•ä¼šå‡ºç° <code>requirements.txt</code> å…¶ä¸­åŒ…å«ç¯å¢ƒä¸­çš„å„ç§ <code>package</code></p>
<h3 id="å®‰è£…è¯­æ³•ğŸ¶"><a href="#å®‰è£…è¯­æ³•ğŸ¶" class="headerlink" title="å®‰è£…è¯­æ³•ğŸ¶"></a>å®‰è£…è¯­æ³•ğŸ¶</h3><p><code>pip install -r</code> å°†ä¼šè‡ªåŠ¨å®‰è£… <code>requirements.txt</code> ä¸­çš„æ‰€æœ‰ <code>package</code></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">pip install -r requirements.txt</span><br></pre></td></tr></table></figure>

<h3 id="requirements-txt-ç»“æ„"><a href="#requirements-txt-ç»“æ„" class="headerlink" title="requirements.txt ç»“æ„"></a>requirements.txt ç»“æ„</h3><ul>
<li><p>Commentsï¼šA line that begins with <code>#</code> is treated as a comment and ignored.</p>
</li>
<li><p>Encodingï¼šRequirements files are <code>utf-8</code> encoding by default</p>
</li>
<li><p>Line continuationsï¼ˆç»­è¡Œï¼‰ï¼šA line ending in an unescaped <code>\</code> is treated as a line continuation</p>
</li>
</ul>
<h3 id="requirements-txt-ä¾‹"><a href="#requirements-txt-ä¾‹" class="headerlink" title="requirements.txt ä¾‹"></a>requirements.txt ä¾‹</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">###### Requirements with Version Specifiers ######</span></span><br><span class="line"><span class="comment">#   See https://www.python.org/dev/peps/pep-0440/#version-specifiers</span></span><br><span class="line">docopt == <span class="number">0.6</span><span class="number">.1</span>             <span class="comment"># Version Matching. Must be version 0.6.1</span></span><br><span class="line">keyring &gt;= <span class="number">4.1</span><span class="number">.1</span>            <span class="comment"># Minimum version 4.1.1</span></span><br><span class="line">coverage != <span class="number">3.5</span>             <span class="comment"># Version Exclusion. Anything except version 3.5</span></span><br><span class="line">Mopidy-Dirble ~= <span class="number">1.1</span>        <span class="comment"># Compatible release. Same as &gt;= 1.1, == 1.*</span></span><br></pre></td></tr></table></figure>

<p><a href="https://github.com/ultralytics/yolov5/blob/master/requirements.txt">ä¸€ä¸ªä¾‹å­</a></p>
]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>pip</tag>
      </tags>
  </entry>
  <entry>
    <title>pyYAML Usage</title>
    <url>/blog/2021/12/11/pyYAML/pyYAML/</url>
    <content><![CDATA[<h1 id="pyYAML-Usage"><a href="#pyYAML-Usage" class="headerlink" title="pyYAML Usage"></a>pyYAML Usage</h1><p>ä½¿ç”¨ yaml æ–‡ä»¶é…ç½®æ¨¡å‹ä»¥åŠè®­ç»ƒå‚æ•°ï¼Œæ–¹ä¾¿è°ƒå‚æ•°ï¼ğŸ˜‰</p>
<p>å€Ÿé‰´æ–‡ç« ï¼š<a href="https://zhuanlan.zhihu.com/p/42678768">https://zhuanlan.zhihu.com/p/42678768</a></p>
<span id="more"></span>

<h2 id="å®‰è£…"><a href="#å®‰è£…" class="headerlink" title="å®‰è£…"></a>å®‰è£…</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">pip install PyYAML</span><br></pre></td></tr></table></figure>

<h2 id="YAML-åŸºæœ¬è¯­æ³•"><a href="#YAML-åŸºæœ¬è¯­æ³•" class="headerlink" title="YAML åŸºæœ¬è¯­æ³•"></a>YAML åŸºæœ¬è¯­æ³•</h2><ul>
<li><p>ä¸Pythonä¸€æ ·é‡‡ç”¨ç¼©è¿›åŒºåˆ†å±‚çº§ï¼Œéœ€è¦åŒä¸€å±‚çº§æ–‡ä»¶ç¼©è¿›ç›¸åŒï¼Œä½†æ˜¯ä¸èƒ½ç”¨TABï¼Œåªèƒ½ä½¿ç”¨ç©ºæ ¼ï¼›</p>
</li>
<li><p><code>#</code> è¡¨ç¤ºæ³¨é‡Šï¼Œä»å®ƒå¼€å§‹åˆ°è¡Œå°¾éƒ½è¢«å¿½ç•¥ï¼›</p>
</li>
<li><p>å¤§å°å†™æ•æ„Ÿï¼›</p>
</li>
<li><p> <code>-</code> å¼€å¤´ï¼Œæ•´ä¸ªæ–‡ä»¶ä¼šè¢«è½¬æ¢ä¸ºlistï¼Œå…¶ä¸­ <code>-</code> åçš„å†…å®¹å±äºä¸€ä¸ªå­—å…¸ï¼›</p>
</li>
<li><p><code>:</code> å‰åçš„å†…å®¹è½¬æ¢ä¸º dictionary çš„é”®å€¼å¯¹ï¼›</p>
</li>
<li><p>å•å¼•å·å†…çš„å†…å®¹æŒ‰ç…§å­—ç¬¦ä¸²è¾“å‡ºï¼Œä¸ä¼šå˜æˆè½¬ç§»å­—ç¬¦ï¼ŒåŒå¼•å·å†…å†…å®¹å­˜åœ¨è½¬ä¹‰å­—ç¬¦ä¼šè½¬æ¢</p>
</li>
</ul>
<h3 id="list"><a href="#list" class="headerlink" title="list"></a>list</h3><blockquote>
<p>parameters.yaml å†…å®¹ &amp; .pyï¼š</p>
</blockquote>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># exchange to list</span></span><br><span class="line"><span class="bullet">-</span> <span class="string">a</span></span><br><span class="line"><span class="bullet">-</span> <span class="string">b</span></span><br><span class="line"><span class="bullet">-</span> <span class="string">c</span></span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> yaml</span><br><span class="line"><span class="keyword">from</span> yaml <span class="keyword">import</span> CLoader <span class="keyword">as</span> Loader</span><br><span class="line"></span><br><span class="line">f = <span class="built_in">open</span>(<span class="string">&#x27;parameters.yml&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line">para = yaml.load(f, Loader)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>(para))</span><br><span class="line"><span class="built_in">print</span>(para)</span><br></pre></td></tr></table></figure>

<p>è¾“å‡ºï¼š</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">&lt;class &#x27;list&#x27;&gt;</span><br><span class="line">[&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;]</span><br></pre></td></tr></table></figure>

<h3 id="dictionary"><a href="#dictionary" class="headerlink" title="dictionary"></a>dictionary</h3><blockquote>
<p>.yml &amp; .py</p>
</blockquote>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># exchange to dictionary</span></span><br><span class="line"><span class="attr">name:</span> <span class="string">zhangsan</span></span><br><span class="line"><span class="attr">age:</span> <span class="number">30</span></span><br><span class="line"><span class="attr">nation:</span> <span class="string">China</span></span><br></pre></td></tr></table></figure>

<p>è¾“å‡ºï¼š</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">&lt;class &#x27;dict&#x27;&gt;</span><br><span class="line">&#123;&#x27;name&#x27;: &#x27;zhangsan&#x27;, &#x27;age&#x27;: 30, &#x27;nation&#x27;: &#x27;China&#x27;&#125;</span><br></pre></td></tr></table></figure>

<h3 id="æ··åˆè½¬æ¢"><a href="#æ··åˆè½¬æ¢" class="headerlink" title="æ··åˆè½¬æ¢"></a>æ··åˆè½¬æ¢</h3><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># exchange to dictionary</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">zhangsan</span></span><br><span class="line">  <span class="attr">age:</span> <span class="number">30</span></span><br><span class="line">  <span class="attr">nation:</span> <span class="string">China</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">lisi</span></span><br><span class="line">  <span class="attr">age:</span> <span class="number">20</span></span><br><span class="line">  <span class="attr">nation:</span> <span class="string">China</span></span><br></pre></td></tr></table></figure>

<p>è¾“å‡ºï¼š</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">&lt;class &#x27;list&#x27;&gt;</span><br><span class="line">[&#123;&#x27;name&#x27;: &#x27;zhangsan&#x27;, &#x27;age&#x27;: 30, &#x27;nation&#x27;: &#x27;China&#x27;&#125;,</span><br><span class="line"> &#123;&#x27;name&#x27;: &#x27;lisi&#x27;, &#x27;age&#x27;: 20, &#x27;nation&#x27;: &#x27;China&#x27;&#125;]</span><br></pre></td></tr></table></figure>

<h2 id="pyYAML-Usage-1"><a href="#pyYAML-Usage-1" class="headerlink" title="pyYAML Usage"></a>pyYAML Usage</h2><h3 id="import-package"><a href="#import-package" class="headerlink" title="import package"></a>import package</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> yaml  <span class="comment"># import this package</span></span><br></pre></td></tr></table></figure>

<h3 id="load"><a href="#load" class="headerlink" title="load()"></a>load()</h3><blockquote>
<p>åŠ è½½ yaml æ–‡ä»¶ï¼Œè¿”å›ä¸€ä¸ª pyYAML å¯¹è±¡ï¼Œè¿™ä¸ªå¯¹è±¡æ˜¯ä¸€ä¸ªåŒ…å«äº†é”®å€¼å¯¹çš„ <code>list</code> æˆ– <code>dict</code></p>
</blockquote>
<p>æˆ‘ä»¬ä¸€èˆ¬ä½¿ç”¨ <code>load()</code> å°±å¤Ÿäº†</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> yaml</span><br><span class="line"><span class="keyword">from</span> yaml <span class="keyword">import</span> CLoader <span class="keyword">as</span> Loader</span><br><span class="line"></span><br><span class="line">f = <span class="built_in">open</span>(<span class="string">&#x27;parameters.yml&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line">para = yaml.load(f, Loader)</span><br><span class="line">total_epoch = para[<span class="string">&#x27;total_epochs&#x27;</span>]</span><br><span class="line">batch_size = para[<span class="string">&#x27;batch_size&#x27;</span>]</span><br><span class="line">learning_rate = <span class="built_in">float</span>(para[<span class="string">&#x27;lr&#x27;</span>])</span><br><span class="line">target_acc = para[<span class="string">&#x27;target_acc&#x27;</span>]</span><br><span class="line">model_name = para[<span class="string">&#x27;model&#x27;</span>]</span><br><span class="line">dataset = para[<span class="string">&#x27;dataset&#x27;</span>]</span><br></pre></td></tr></table></figure>

<h3 id="dump"><a href="#dump" class="headerlink" title="dump()"></a>dump()</h3><blockquote>
<p>å°†é”®å€¼å¯¹ï¼Œè½¬æ¢æˆ yaml æ ¼å¼</p>
</blockquote>
]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>YAML</tag>
      </tags>
  </entry>
  <entry>
    <title>Transfer Learning</title>
    <url>/blog/2021/12/25/%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0/1.0%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0/</url>
    <content><![CDATA[<h1 id="è¿ç§»å­¦ä¹ å’Œå¾®è°ƒï¼ˆkerasï¼‰"><a href="#è¿ç§»å­¦ä¹ å’Œå¾®è°ƒï¼ˆkerasï¼‰" class="headerlink" title="è¿ç§»å­¦ä¹ å’Œå¾®è°ƒï¼ˆkerasï¼‰"></a>è¿ç§»å­¦ä¹ å’Œå¾®è°ƒï¼ˆkerasï¼‰</h1><span id="more"></span>

<h2 id="import-setting"><a href="#import-setting" class="headerlink" title="import setting!"></a><strong>import setting!</strong></h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras</span><br></pre></td></tr></table></figure>

<h2 id="introduce"><a href="#introduce" class="headerlink" title="introduce"></a>introduce</h2><p><strong>è¿ç§»å­¦ä¹ </strong>åŒ…æ‹¬è·å–ä»ä¸€ä¸ªé—®é¢˜ä¸­å­¦ä¹ åˆ°çš„ç‰¹å¾ï¼Œç„¶åå°†è¿™äº›ç‰¹å¾ç”¨äºæ–°çš„ç±»ä¼¼é—®é¢˜ã€‚ä¾‹å¦‚ï¼Œæ¥è‡ªå·²å­¦ä¼šè¯†åˆ«æµ£ç†Šçš„æ¨¡å‹çš„ç‰¹å¾å¯èƒ½å¯¹å»ºç«‹æ—¨åœ¨è¯†åˆ«ç‹¸çŒ«çš„æ¨¡å‹ååˆ†æœ‰ç”¨ã€‚</p>
<p>å¯¹äºæ•°æ®é›†ä¸­çš„æ•°æ®å¤ªå°‘è€Œæ— æ³•ä»å¤´å¼€å§‹è®­ç»ƒå®Œæ•´æ¨¡å‹çš„ä»»åŠ¡ï¼Œé€šå¸¸ä¼šæ‰§è¡Œè¿ç§»å­¦ä¹ </p>
<p>åœ¨æ·±åº¦å­¦ä¹ æƒ…å¢ƒä¸­ï¼Œè¿ç§»å­¦ä¹ æœ€å¸¸è§çš„å½¢å¼æ˜¯ä»¥ä¸‹å·¥ä½œæµï¼š</p>
<ul>
<li><p>ä»ä¹‹å‰è®­ç»ƒçš„æ¨¡å‹ä¸­è·å–å±‚ã€‚</p>
</li>
<li><p>å†»ç»“è¿™äº›å±‚ï¼Œä»¥é¿å…åœ¨åç»­è®­ç»ƒè½®æ¬¡ä¸­ç ´åå®ƒä»¬åŒ…å«çš„ä»»ä½•ä¿¡æ¯ã€‚</p>
</li>
<li><p>åœ¨å·²å†»ç»“å±‚çš„<strong>é¡¶éƒ¨</strong>æ·»åŠ ä¸€äº›æ–°çš„å¯è®­ç»ƒå±‚ã€‚è¿™äº›å±‚ä¼šå­¦ä¹ å°†æ—§ç‰¹å¾è½¬æ¢ä¸ºå¯¹æ–°æ•°æ®é›†çš„é¢„æµ‹ã€‚</p>
</li>
<li><p>åœ¨æ‚¨çš„æ•°æ®é›†ä¸Šè®­ç»ƒæ–°å±‚ã€‚</p>
</li>
</ul>
<p>æœ€åä¸€ä¸ªå¯é€‰æ­¥éª¤æ˜¯<strong>å¾®è°ƒ</strong>ï¼ŒåŒ…æ‹¬è§£å†»ä¸Šé¢è·å¾—çš„æ•´ä¸ªæ¨¡å‹ï¼ˆæˆ–æ¨¡å‹çš„ä¸€éƒ¨åˆ†ï¼‰ï¼Œç„¶ååœ¨æ–°æ•°æ®ä¸Šä»¥<strong>æä½çš„å­¦ä¹ ç‡</strong>å¯¹è¯¥æ¨¡å‹è¿›è¡Œé‡æ–°è®­ç»ƒã€‚ä»¥å¢é‡æ–¹å¼ä½¿é¢„è®­ç»ƒç‰¹å¾é€‚åº”æ–°æ•°æ®ï¼Œæœ‰å¯èƒ½å®ç°æœ‰æ„ä¹‰çš„æ”¹è¿›ã€‚</p>
<p>é¦–å…ˆï¼Œæˆ‘ä»¬å°†è¯¦ç»†ä»‹ç» Keras <code>trainable</code> APIï¼Œå®ƒæ˜¯å¤§å¤šæ•°è¿ç§»å­¦ä¹ å’Œå¾®è°ƒå·¥ä½œæµçš„åŸºç¡€ã€‚</p>
<p>éšåï¼Œæˆ‘ä»¬å°†æ¼”ç¤ºä¸€ä¸ªå…¸å‹å·¥ä½œæµï¼šå…ˆè·å¾—ä¸€ä¸ªåœ¨ ImageNet æ•°æ®é›†ä¸Šé¢„è®­ç»ƒçš„æ¨¡å‹ï¼Œç„¶ååœ¨ Kaggle Dogs vs. Cats åˆ†ç±»æ•°æ®é›†ä¸Šå¯¹è¯¥æ¨¡å‹è¿›è¡Œé‡æ–°è®­ç»ƒã€‚</p>
<h2 id="å†»ç»“å±‚ï¼šäº†è§£-trainable-ç‰¹æ€§"><a href="#å†»ç»“å±‚ï¼šäº†è§£-trainable-ç‰¹æ€§" class="headerlink" title="å†»ç»“å±‚ï¼šäº†è§£ trainable ç‰¹æ€§"></a>å†»ç»“å±‚ï¼šäº†è§£ <code>trainable</code> ç‰¹æ€§</h2><p>å±‚å’Œæ¨¡å‹å…·æœ‰ä¸‰ä¸ªæƒé‡ç‰¹æ€§ï¼š</p>
<ul>
<li><p><code>weights</code> æ˜¯å±‚çš„æ‰€æœ‰æƒé‡å˜é‡çš„åˆ—è¡¨ã€‚</p>
</li>
<li><p><code>trainable_weights</code> æ˜¯éœ€è¦è¿›è¡Œæ›´æ–°ï¼ˆé€šè¿‡æ¢¯åº¦ä¸‹é™ï¼‰ä»¥å°½å¯èƒ½å‡å°‘è®­ç»ƒè¿‡ç¨‹ä¸­æŸå¤±çš„æƒé‡åˆ—è¡¨ã€‚</p>
</li>
<li><p><code>non_trainable_weights</code> æ˜¯ä¸é€‚åˆè®­ç»ƒçš„æƒé‡åˆ—è¡¨ã€‚å®ƒä»¬é€šå¸¸åœ¨æ­£å‘ä¼ é€’è¿‡ç¨‹ä¸­ç”±æ¨¡å‹æ›´æ–°ã€‚</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">layer = keras.layers.Dense(<span class="number">3</span>)</span><br><span class="line">layer.build((<span class="literal">None</span>, <span class="number">4</span>))  <span class="comment"># Create the weights (build()&#x27;s paras: input_sahpe)</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;weights:&quot;</span>, <span class="built_in">len</span>(layer.weights))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;trainable_weights:&quot;</span>, <span class="built_in">len</span>(layer.trainable_weights))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;non_trainable_weights:&quot;</span>, <span class="built_in">len</span>(layer.non_trainable_weights))</span><br><span class="line"></span><br><span class="line"><span class="comment"># output</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">weights: 2</span></span><br><span class="line"><span class="string">trainable_weights: 2</span></span><br><span class="line"><span class="string">non_trainable_weights: 0</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>

<p>ä¸€èˆ¬è€Œè¨€ï¼Œæ‰€æœ‰æƒé‡éƒ½æ˜¯å¯è®­ç»ƒæƒé‡ã€‚å”¯ä¸€å…·æœ‰ä¸å¯è®­ç»ƒæƒé‡çš„å†…ç½®å±‚æ˜¯ <code>BatchNormalization</code> å±‚ã€‚åœ¨è®­ç»ƒæœŸé—´ï¼Œå®ƒä½¿ç”¨ä¸å¯è®­ç»ƒæƒé‡è·Ÿè¸ªå…¶è¾“å…¥çš„å¹³å‡å€¼å’Œæ–¹å·®ã€‚</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">layer = keras.layers.BatchNormalization()</span><br><span class="line">layer.build((<span class="literal">None</span>, <span class="number">4</span>))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;weights:&quot;</span>, <span class="built_in">len</span>(layer.weights))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;trainable_weights:&quot;</span>, <span class="built_in">len</span>(layer.trainable_weights))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;non_trainable_weights:&quot;</span>, <span class="built_in">len</span>(layer.non_trainable_weights))</span><br><span class="line"></span><br><span class="line"><span class="comment"># output</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">weights: 4</span></span><br><span class="line"><span class="string">trainable_weights: 2</span></span><br><span class="line"><span class="string">non_trainable_weights: 2</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>

<p>å±‚å’Œæ¨¡å‹è¿˜å…·æœ‰å¸ƒå°”ç‰¹æ€§ <code>trainable</code>ğŸ’¥ã€‚æ­¤ç‰¹æ€§çš„å€¼å¯ä»¥æ›´æ”¹ã€‚å°† <code>layer.trainable</code> è®¾ç½®ä¸º <code>False</code> ä¼šå°†å±‚çš„æ‰€æœ‰æƒé‡ä»å¯è®­ç»ƒç§»è‡³ä¸å¯è®­ç»ƒã€‚è¿™ä¸€è¿‡ç¨‹ç§°ä¸ºâ€œå†»ç»“â€å±‚ï¼šå·²å†»ç»“å±‚çš„çŠ¶æ€åœ¨è®­ç»ƒæœŸé—´ä¸ä¼šæ›´æ–°ï¼ˆæ— è®ºæ˜¯ä½¿ç”¨ <code>fit()</code> è¿›è¡Œè®­ç»ƒï¼Œè¿˜æ˜¯ä½¿ç”¨ä¾èµ–äº <code>trainable_weights</code> æ¥åº”ç”¨æ¢¯åº¦æ›´æ–°çš„ä»»ä½•è‡ªå®šä¹‰å¾ªç¯è¿›è¡Œè®­ç»ƒæ—¶ï¼‰ã€‚</p>
<h3 id="ç¤ºä¾‹ï¼šå°†-trainable-è®¾ç½®ä¸º-False"><a href="#ç¤ºä¾‹ï¼šå°†-trainable-è®¾ç½®ä¸º-False" class="headerlink" title="ç¤ºä¾‹ï¼šå°† trainable è®¾ç½®ä¸º False"></a><strong>ç¤ºä¾‹ï¼šå°† <code>trainable</code> è®¾ç½®ä¸º <code>False</code></strong></h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">layer = keras.layers.Dense(<span class="number">3</span>)</span><br><span class="line">layer.build((<span class="literal">None</span>, <span class="number">4</span>))</span><br><span class="line">layer.trainable = <span class="literal">False</span>  <span class="comment"># Freeze the layer</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;weights:&quot;</span>, <span class="built_in">len</span>(layer.weights))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;trainable_weights:&quot;</span>, <span class="built_in">len</span>(layer.trainable_weights))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;non_trainable_weights:&quot;</span>, <span class="built_in">len</span>(layer.non_trainable_weights))</span><br><span class="line"><span class="comment"># output</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">weights: 2</span></span><br><span class="line"><span class="string">trainable_weights: 0</span></span><br><span class="line"><span class="string">non_trainable_weights: 2</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>

<p><strong>å½“å¯è®­ç»ƒæƒé‡å˜ä¸ºä¸å¯è®­ç»ƒæ—¶ï¼Œå®ƒçš„å€¼åœ¨è®­ç»ƒæœŸé—´ä¸å†æ›´æ–°ã€‚</strong>ğŸ‘</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Make a model with 2 layers</span></span><br><span class="line">layer1 = keras.layers.Dense(<span class="number">3</span>, activation=<span class="string">&quot;relu&quot;</span>)</span><br><span class="line">layer2 = keras.layers.Dense(<span class="number">3</span>, activation=<span class="string">&quot;sigmoid&quot;</span>)</span><br><span class="line">model = keras.Sequential([keras.Input(shape=(<span class="number">3</span>,)), layer1, layer2])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Freeze the first layer</span></span><br><span class="line">layer1.trainable = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Keep a copy of the weights of layer1 for later reference</span></span><br><span class="line">initial_layer1_weights_values = layer1.get_weights()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Train the model</span></span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=<span class="string">&quot;adam&quot;</span>, loss=<span class="string">&quot;mse&quot;</span>)</span><br><span class="line">model.fit(np.random.random((<span class="number">2</span>, <span class="number">3</span>)), np.random.random((<span class="number">2</span>, <span class="number">3</span>)))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Check that the weights of layer1 have not changed during training</span></span><br><span class="line">final_layer1_weights_values = layer1.get_weights()</span><br><span class="line">np.testing.assert_allclose(</span><br><span class="line">    initial_layer1_weights_values[<span class="number">0</span>], final_layer1_weights_values[<span class="number">0</span>]</span><br><span class="line">)</span><br><span class="line">np.testing.assert_allclose(</span><br><span class="line">    initial_layer1_weights_values[<span class="number">1</span>], final_layer1_weights_values[<span class="number">1</span>]</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># output</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">1/1 [==============================] - 1s 615ms/step - loss: 0.0895</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>

<p>è¯·å‹¿å°† <code>layer.trainable</code> ç‰¹æ€§ä¸ <code>layer.__call__()</code> ä¸­çš„ <code>training</code> å‚æ•°ï¼ˆæ­¤å‚æ•°æ§åˆ¶å±‚æ˜¯åœ¨æ¨æ–­æ¨¡å¼è¿˜æ˜¯è®­ç»ƒæ¨¡å¼ä¸‹è¿è¡Œå…¶å‰å‘ä¼ é€’ï¼‰æ··æ·†ã€‚</p>
<h3 id="trainable-ç‰¹æ€§çš„é€’å½’è®¾ç½®"><a href="#trainable-ç‰¹æ€§çš„é€’å½’è®¾ç½®" class="headerlink" title="trainable ç‰¹æ€§çš„é€’å½’è®¾ç½®"></a><code>trainable</code> ç‰¹æ€§çš„é€’å½’è®¾ç½®</h3><p>å¦‚æœåœ¨æ¨¡å‹æˆ–å…·æœ‰å­å±‚çš„ä»»ä½•å±‚ä¸Šè®¾ç½® <code>trainable = False</code>ï¼Œåˆ™æ‰€æœ‰å­å±‚ä¹Ÿå°†å˜ä¸ºä¸å¯è®­ç»ƒã€‚</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">inner_model = keras.Sequential(</span><br><span class="line">    [</span><br><span class="line">        keras.Input(shape=(<span class="number">3</span>,)),</span><br><span class="line">        keras.layers.Dense(<span class="number">3</span>, activation=<span class="string">&quot;relu&quot;</span>),</span><br><span class="line">        keras.layers.Dense(<span class="number">3</span>, activation=<span class="string">&quot;relu&quot;</span>),</span><br><span class="line">    ]</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">model = keras.Sequential(</span><br><span class="line">    [keras.Input(shape=(<span class="number">3</span>,)), inner_model, keras.layers.Dense(<span class="number">3</span>, activation=<span class="string">&quot;sigmoid&quot;</span>),]</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">model.trainable = <span class="literal">False</span>  <span class="comment"># Freeze the outer model</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">assert</span> inner_model.trainable == <span class="literal">False</span>  <span class="comment"># All layers in `model` are now frozen</span></span><br><span class="line"><span class="keyword">assert</span> inner_model.layers[<span class="number">0</span>].trainable == <span class="literal">False</span>  <span class="comment"># `trainable` is propagated recursively</span></span><br></pre></td></tr></table></figure>

<h2 id="å…¸å‹çš„è¿ç§»å­¦ä¹ å·¥ä½œæµ"><a href="#å…¸å‹çš„è¿ç§»å­¦ä¹ å·¥ä½œæµ" class="headerlink" title="å…¸å‹çš„è¿ç§»å­¦ä¹ å·¥ä½œæµ"></a>å…¸å‹çš„è¿ç§»å­¦ä¹ å·¥ä½œæµ</h2><p>ä¸‹é¢å°†ä»‹ç»å¦‚ä½•åœ¨ Keras ä¸­å®ç°å…¸å‹çš„è¿ç§»å­¦ä¹ å·¥ä½œæµğŸ‘ï¼š</p>
<ul>
<li><p>å®ä¾‹åŒ–ä¸€ä¸ªåŸºç¡€æ¨¡å‹å¹¶åŠ è½½é¢„è®­ç»ƒæƒé‡ã€‚</p>
</li>
<li><p>é€šè¿‡è®¾ç½® <code>trainable = False</code> å†»ç»“åŸºç¡€æ¨¡å‹ä¸­çš„æ‰€æœ‰å±‚ã€‚</p>
</li>
<li><p>æ ¹æ®åŸºç¡€æ¨¡å‹ä¸­ä¸€ä¸ªï¼ˆæˆ–å¤šä¸ªï¼‰å±‚çš„è¾“å‡ºåˆ›å»ºä¸€ä¸ªæ–°æ¨¡å‹ã€‚</p>
</li>
<li><p>åœ¨æ‚¨çš„æ–°æ•°æ®é›†ä¸Šè®­ç»ƒæ–°æ¨¡å‹ã€‚</p>
</li>
</ul>
<p>è¯·æ³¨æ„ï¼Œå¦ä¸€ç§æ›´è½»é‡çš„å·¥ä½œæµå¦‚ä¸‹ğŸ˜Šï¼š</p>
<ul>
<li><p>å®ä¾‹åŒ–ä¸€ä¸ªåŸºç¡€æ¨¡å‹å¹¶åŠ è½½é¢„è®­ç»ƒæƒé‡ã€‚</p>
</li>
<li><p>é€šè¿‡è¯¥æ¨¡å‹è¿è¡Œæ–°çš„æ•°æ®é›†ï¼Œå¹¶è®°å½•åŸºç¡€æ¨¡å‹ä¸­ä¸€ä¸ªï¼ˆæˆ–å¤šä¸ªï¼‰å±‚çš„è¾“å‡ºã€‚è¿™ä¸€è¿‡ç¨‹ç§°ä¸º<strong>ç‰¹å¾æå–</strong>ã€‚</p>
</li>
<li><p>ä½¿ç”¨è¯¥è¾“å‡ºä½œä¸ºæ–°çš„è¾ƒå°æ¨¡å‹çš„è¾“å…¥æ•°æ®ã€‚</p>
</li>
</ul>
<p>ç¬¬äºŒç§å·¥ä½œæµæœ‰ä¸€ä¸ªå…³é”®ä¼˜åŠ¿ï¼Œå³æ‚¨åªéœ€åœ¨è‡ªå·±çš„æ•°æ®ä¸Šè¿è¡Œä¸€æ¬¡åŸºç¡€æ¨¡å‹ï¼Œè€Œä¸æ˜¯æ¯ä¸ªè®­ç»ƒå‘¨æœŸéƒ½è¿è¡Œä¸€æ¬¡ã€‚å› æ­¤ï¼Œå®ƒçš„é€Ÿåº¦æ›´å¿«ï¼Œå¼€é”€ä¹Ÿæ›´ä½ã€‚</p>
<p>ä½†æ˜¯ï¼Œç¬¬äºŒç§å·¥ä½œæµå­˜åœ¨ä¸€ä¸ªé—®é¢˜ï¼Œå³å®ƒä¸å…è®¸æ‚¨åœ¨è®­ç»ƒæœŸé—´åŠ¨æ€ä¿®æ”¹æ–°æ¨¡å‹çš„è¾“å…¥æ•°æ®ï¼Œåœ¨è¿›è¡Œæ•°æ®æ‰©å……æ—¶ï¼Œè¿™ç§ä¿®æ”¹å¿…ä¸å¯å°‘ã€‚å½“æ–°æ•°æ®é›†çš„æ•°æ®å¤ªå°‘è€Œæ— æ³•ä»å¤´å¼€å§‹è®­ç»ƒå®Œæ•´æ¨¡å‹æ—¶ï¼Œä»»åŠ¡é€šå¸¸ä¼šä½¿ç”¨è¿ç§»å­¦ä¹ ï¼Œåœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæ•°æ®æ‰©å……éå¸¸é‡è¦ã€‚å› æ­¤ï¼Œåœ¨æ¥ä¸‹æ¥çš„ç¯‡å¹…ä¸­ï¼Œæˆ‘ä»¬å°†ä¸“æ³¨äºç¬¬ä¸€ç§å·¥ä½œæµã€‚</p>
<p>ä¸‹é¢æ˜¯ Keras ä¸­ç¬¬ä¸€ç§å·¥ä½œæµçš„æ ·å­ï¼š</p>
<ol>
<li>é¦–å…ˆï¼Œå®ä¾‹åŒ–ä¸€ä¸ªå…·æœ‰é¢„è®­ç»ƒæƒé‡çš„åŸºç¡€æ¨¡å‹ã€‚</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">base_model = keras.applications.Xception(</span><br><span class="line">    weights=<span class="string">&#x27;imagenet&#x27;</span>,  <span class="comment"># Load weights pre-trained on ImageNet.</span></span><br><span class="line">    input_shape=(<span class="number">150</span>, <span class="number">150</span>, <span class="number">3</span>),</span><br><span class="line">    include_top=<span class="literal">False</span>)  <span class="comment"># Do not include the ImageNet classifier at the top.</span></span><br></pre></td></tr></table></figure>

<ol start="2">
<li>éšåï¼Œå†»ç»“è¯¥åŸºç¡€æ¨¡å‹ã€‚</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">base_model.trainable = <span class="literal">False</span></span><br></pre></td></tr></table></figure>

<ol start="3">
<li>æ ¹æ®åŸºç¡€æ¨¡å‹åˆ›å»ºä¸€ä¸ªæ–°æ¨¡å‹ã€‚</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">inputs = keras.Input(shape=(<span class="number">150</span>, <span class="number">150</span>, <span class="number">3</span>))</span><br><span class="line"><span class="comment"># We make sure that the base_model is running in inference mode here,</span></span><br><span class="line"><span class="comment"># by passing `training=False`. This is important for fine-tuning, as you will</span></span><br><span class="line"><span class="comment"># learn in a few paragraphs.</span></span><br><span class="line">x = base_model(inputs, training=<span class="literal">False</span>)</span><br><span class="line"><span class="comment"># Convert features of shape `base_model.output_shape[1:]` to vectors</span></span><br><span class="line">x = keras.layers.GlobalAveragePooling2D()(x)</span><br><span class="line"><span class="comment"># A Dense classifier with a single unit (binary classification)</span></span><br><span class="line">outputs = keras.layers.Dense(<span class="number">1</span>)(x)</span><br><span class="line">model = keras.Model(inputs, outputs)</span><br></pre></td></tr></table></figure>

<ol start="4">
<li>åœ¨æ–°æ•°æ®ä¸Šè®­ç»ƒè¯¥æ¨¡å‹ã€‚</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model.<span class="built_in">compile</span>(optimizer=keras.optimizers.Adam(),</span><br><span class="line">              loss=keras.losses.BinaryCrossentropy(from_logits=<span class="literal">True</span>),</span><br><span class="line">              metrics=[keras.metrics.BinaryAccuracy()])</span><br><span class="line">model.fit(new_dataset, epochs=<span class="number">20</span>, callbacks=..., validation_data=...)</span><br></pre></td></tr></table></figure>

<h2 id="å¾®è°ƒ"><a href="#å¾®è°ƒ" class="headerlink" title="å¾®è°ƒ"></a>å¾®è°ƒ</h2><p>ä¸€æ—¦æ¨¡å‹åœ¨æ–°æ•°æ®ä¸Šæ”¶æ•›ï¼Œæ‚¨å°±å¯ä»¥å°è¯•è§£å†»å…¨éƒ¨æˆ–éƒ¨åˆ†åŸºç¡€æ¨¡å‹ï¼Œå¹¶ä»¥<strong>æä½çš„å­¦ä¹ ç‡</strong>ç«¯åˆ°ç«¯åœ°é‡æ–°è®­ç»ƒæ•´ä¸ªæ¨¡å‹ã€‚</p>
<p>è¿™æ˜¯å¯é€‰çš„æœ€åä¸€ä¸ªæ­¥éª¤ï¼Œå¯èƒ½ç»™æ‚¨å¸¦æ¥å¢é‡å¼æ”¹è¿›ã€‚ä¸è¿‡ï¼Œå®ƒä¹Ÿå¯èƒ½å¯¼è‡´<strong>å¿«é€Ÿè¿‡æ‹Ÿåˆ</strong>ï¼Œè¯·ç‰¢è®°è¿™ä¸€ç‚¹ã€‚</p>
<p>é‡è¦çš„æ˜¯ï¼Œåªæœ‰åœ¨å°†å…·æœ‰å†»ç»“å±‚çš„æ¨¡å‹è®­ç»ƒè‡³æ”¶æ•›<em>å</em>ï¼Œæ‰èƒ½æ‰§è¡Œæ­¤æ­¥éª¤ã€‚å¦‚æœå°†éšæœºåˆå§‹åŒ–çš„å¯è®­ç»ƒå±‚ä¸åŒ…å«é¢„è®­ç»ƒç‰¹å¾çš„å¯è®­ç»ƒå±‚æ··åˆä½¿ç”¨ï¼Œåˆ™éšæœºåˆå§‹åŒ–çš„å±‚å°†åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å¼•èµ·éå¸¸å¤§çš„æ¢¯åº¦æ›´æ–°ï¼Œè€Œè¿™å°†ç ´åæ‚¨çš„é¢„è®­ç»ƒç‰¹å¾ã€‚</p>
<p>åœ¨æ­¤é˜¶æ®µä½¿ç”¨æä½çš„å­¦ä¹ ç‡ä¹Ÿå¾ˆé‡è¦ï¼Œå› ä¸ºä¸ç¬¬ä¸€è½®è®­ç»ƒç›¸æ¯”ï¼Œæ‚¨æ­£åœ¨ä¸€ä¸ªé€šå¸¸éå¸¸å°çš„æ•°æ®é›†ä¸Šè®­ç»ƒä¸€ä¸ªå¤§å¾—å¤šçš„æ¨¡å‹ã€‚å› æ­¤ï¼Œå¦‚æœæ‚¨åº”ç”¨è¾ƒå¤§çš„æƒé‡æ›´æ–°ï¼Œåˆ™å­˜åœ¨å¾ˆå¿«è¿‡æ‹Ÿåˆçš„é£é™©ã€‚åœ¨è¿™é‡Œï¼Œæ‚¨åªéœ€è¦ä»¥å¢é‡æ–¹å¼é‡æ–°è°ƒæ•´é¢„è®­ç»ƒæƒé‡ã€‚</p>
<p>ä¸‹é¢æ˜¯å®ç°æ•´ä¸ªåŸºç¡€æ¨¡å‹å¾®è°ƒçš„æ–¹æ³•ï¼š</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Unfreeze the base model</span></span><br><span class="line">base_model.trainable = <span class="literal">True</span>  <span class="comment"># å…ˆæŠŠæ¨¡å‹è§£å†»ï¼ï¼ï¼</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># It&#x27;s important to recompile your model after you make any changes</span></span><br><span class="line"><span class="comment"># to the `trainable` attribute of any inner layer, so that your changes</span></span><br><span class="line"><span class="comment"># are take into account</span></span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=keras.optimizers.Adam(<span class="number">1e-5</span>),  <span class="comment"># Very low learning rate</span></span><br><span class="line">              loss=keras.losses.BinaryCrossentropy(from_logits=<span class="literal">True</span>),</span><br><span class="line">              metrics=[keras.metrics.BinaryAccuracy()])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Train end-to-end. Be careful to stop before you overfit!</span></span><br><span class="line">model.fit(new_dataset, epochs=<span class="number">10</span>, callbacks=..., validation_data=...)</span><br></pre></td></tr></table></figure>

<p><strong>å…³äº <code>compile()</code> å’Œ <code>trainable</code> çš„é‡è¦è¯´æ˜</strong></p>
<p>åœ¨æ¨¡å‹ä¸Šè°ƒç”¨ <code>compile()</code> æ˜¯ä¸ºäº†â€œå†»ç»“â€è¯¥æ¨¡å‹çš„è¡Œä¸ºã€‚è¿™æ„å‘³ç€åœ¨ç¼–è¯‘æ¨¡å‹æ—¶ï¼Œåº”å½“åœ¨è¯¥æ¨¡å‹çš„æ•´ä¸ªç”Ÿå‘½å‘¨æœŸä¸­ä¿ç•™ <code>trainable</code> ç‰¹æ€§å€¼ï¼Œç›´åˆ°å†æ¬¡è°ƒç”¨ <code>compile</code> ä¸ºæ­¢ã€‚å› æ­¤ï¼Œå¦‚æœæ‚¨æ›´æ”¹äº†ä»»ä½• <code>trainable</code> å€¼ï¼Œè¯·ç¡®ä¿åœ¨æ¨¡å‹ä¸Šå†æ¬¡è°ƒç”¨ <code>compile()</code>ï¼Œå°†è¿™äº›å˜æ›´è€ƒè™‘åœ¨å†…ã€‚</p>
<p><strong>å…³äº <code>BatchNormalization</code> å±‚çš„é‡è¦è¯´æ˜</strong></p>
<p>è®¸å¤šå›¾åƒæ¨¡å‹éƒ½åŒ…å« <code>BatchNormalization</code> å±‚ã€‚åœ¨å„ç§èƒ½æƒ³åˆ°çš„æ•°é‡ä¸Šï¼Œè¯¥å±‚éƒ½æ˜¯ä¸€ä¸ªç‰¹ä¾‹ã€‚éœ€è¦ç‰¢è®°ä»¥ä¸‹å‡ ç‚¹ã€‚</p>
<ul>
<li><code>BatchNormalization</code> åŒ…å« 2 ä¸ªä¼šåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­æ›´æ–°çš„ä¸å¯è®­ç»ƒæƒé‡ã€‚å®ƒä»¬æ˜¯è·Ÿè¸ªè¾“å…¥çš„å¹³å‡å€¼å’Œæ–¹å·®çš„å˜é‡ã€‚</li>
<li>è®¾ç½® <code>bn_layer.trainable = False</code> æ—¶ï¼Œ<code>BatchNormalization</code> å±‚å°†ä»¥æ¨æ–­æ¨¡å¼è¿è¡Œï¼Œå¹¶ä¸”ä¸ä¼šæ›´æ–°å…¶å‡å€¼å’Œæ–¹å·®ç»Ÿè®¡ä¿¡æ¯ã€‚å…¶ä»–å±‚ä¸€èˆ¬ä¸æ˜¯è¿™ç§æƒ…å†µï¼Œå› ä¸º<a href="https://keras.io/getting_started/faq/#whats-the-difference-between-the-training-argument-in-call-and-the-trainable-attribute">æƒé‡å¯è®­ç»ƒæ€§å’Œæ¨æ–­/è®­ç»ƒæ¨¡å¼æ˜¯ä¸¤ä¸ªæ­£äº¤çš„æ¦‚å¿µ</a>ã€‚ä½†æ˜¯å¯¹äº <code>BatchNormalization</code> å±‚ï¼Œä¸¤è€…æ˜¯ç»‘å®šçš„ã€‚</li>
<li>è§£å†»åŒ…å« <code>BatchNormalization</code> å±‚çš„æ¨¡å‹ä»¥è¿›è¡Œå¾®è°ƒæ—¶ï¼Œåº”åœ¨è°ƒç”¨åŸºç¡€æ¨¡å‹æ—¶é€šè¿‡ä¼ é€’ <code>training=False</code> æ¥ä½¿ <code>BatchNormalization</code> å±‚ä¿æŒåœ¨æ¨æ–­æ¨¡å¼ä¸‹ã€‚å¦åˆ™ï¼Œåº”ç”¨äºä¸å¯è®­ç»ƒæƒé‡çš„æ›´æ–°å°†çªç„¶ç ´åæ¨¡å‹å­¦ä¹ åˆ°çš„å†…å®¹ã€‚</li>
</ul>
<p>æ‚¨å°†åœ¨æœ¬æŒ‡å—ç»“å°¾å¤„çš„ç«¯åˆ°ç«¯ç¤ºä¾‹ä¸­çœ‹åˆ°è¿™ç§æ¨¡å¼çš„å®é™…è¿è¡Œã€‚</p>
<h2 id="ä½¿ç”¨è‡ªå®šä¹‰è®­ç»ƒå¾ªç¯è¿›è¡Œè¿ç§»å­¦ä¹ å’Œå¾®è°ƒ"><a href="#ä½¿ç”¨è‡ªå®šä¹‰è®­ç»ƒå¾ªç¯è¿›è¡Œè¿ç§»å­¦ä¹ å’Œå¾®è°ƒ" class="headerlink" title="ä½¿ç”¨è‡ªå®šä¹‰è®­ç»ƒå¾ªç¯è¿›è¡Œè¿ç§»å­¦ä¹ å’Œå¾®è°ƒ"></a>ä½¿ç”¨è‡ªå®šä¹‰è®­ç»ƒå¾ªç¯è¿›è¡Œè¿ç§»å­¦ä¹ å’Œå¾®è°ƒ</h2><p>å¦‚æœæ‚¨ä½¿ç”¨çš„æ˜¯è‡ªå·±çš„ä½çº§è®­ç»ƒå¾ªç¯ï¼Œè€Œä¸æ˜¯ <code>fit()</code>ï¼Œåˆ™å·¥ä½œæµåŸºæœ¬ä¿æŒä¸å˜ã€‚åœ¨åº”ç”¨æ¢¯åº¦æ›´æ–°æ—¶ï¼Œæ‚¨åº”å½“æ³¨æ„ä»…è€ƒè™‘åˆ—è¡¨ <code>model.trainable_weights</code>ï¼š</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Create base model</span></span><br><span class="line">base_model = keras.applications.Xception(</span><br><span class="line">    weights=<span class="string">&#x27;imagenet&#x27;</span>,</span><br><span class="line">    input_shape=(<span class="number">150</span>, <span class="number">150</span>, <span class="number">3</span>),</span><br><span class="line">    include_top=<span class="literal">False</span>)</span><br><span class="line"><span class="comment"># Freeze base model</span></span><br><span class="line">base_model.trainable = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Create new model on top.</span></span><br><span class="line">inputs = keras.Input(shape=(<span class="number">150</span>, <span class="number">150</span>, <span class="number">3</span>))</span><br><span class="line">x = base_model(inputs, training=<span class="literal">False</span>)</span><br><span class="line">x = keras.layers.GlobalAveragePooling2D()(x)</span><br><span class="line">outputs = keras.layers.Dense(<span class="number">1</span>)(x)</span><br><span class="line">model = keras.Model(inputs, outputs)</span><br><span class="line"></span><br><span class="line">loss_fn = keras.losses.BinaryCrossentropy(from_logits=<span class="literal">True</span>)</span><br><span class="line">optimizer = keras.optimizers.Adam()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Iterate over the batches of a dataset.</span></span><br><span class="line"><span class="keyword">for</span> inputs, targets <span class="keyword">in</span> new_dataset:</span><br><span class="line">    <span class="comment"># Open a GradientTape.</span></span><br><span class="line">	<span class="keyword">with</span> tf.GradientTape() <span class="keyword">as</span> tape:</span><br><span class="line">        <span class="comment"># Forward pass.</span></span><br><span class="line">        predictions = model(inputs)</span><br><span class="line">        <span class="comment"># Compute the loss value for this batch.</span></span><br><span class="line">        loss_value = loss_fn(targets, predictions)</span><br><span class="line">    <span class="comment"># Get gradients of loss wrt the *trainable* weights.</span></span><br><span class="line">    gradients = tape.gradient(loss_value, model.trainable_weights)</span><br><span class="line">    <span class="comment"># Update the weights of the model.</span></span><br><span class="line">    optimizer.apply_gradients(<span class="built_in">zip</span>(gradients, model.trainable_weights))   </span><br></pre></td></tr></table></figure>

<p>å¯¹äºå¾®è°ƒåŒæ ·å¦‚æ­¤ã€‚</p>
<h2 id="ç«¯åˆ°ç«¯ç¤ºä¾‹ï¼šåŸºäº-Dogs-vs-Cats-æ•°æ®é›†å¾®è°ƒå›¾åƒåˆ†ç±»æ¨¡å‹"><a href="#ç«¯åˆ°ç«¯ç¤ºä¾‹ï¼šåŸºäº-Dogs-vs-Cats-æ•°æ®é›†å¾®è°ƒå›¾åƒåˆ†ç±»æ¨¡å‹" class="headerlink" title="ç«¯åˆ°ç«¯ç¤ºä¾‹ï¼šåŸºäº Dogs vs. Cats æ•°æ®é›†å¾®è°ƒå›¾åƒåˆ†ç±»æ¨¡å‹"></a>ç«¯åˆ°ç«¯ç¤ºä¾‹ï¼šåŸºäº Dogs vs. Cats æ•°æ®é›†å¾®è°ƒå›¾åƒåˆ†ç±»æ¨¡å‹</h2><p>ä¸ºäº†å·©å›ºè¿™äº›æ¦‚å¿µï¼Œæˆ‘ä»¬å…ˆä»‹ç»ä¸€ä¸ªå…·ä½“çš„ç«¯åˆ°ç«¯è¿ç§»å­¦ä¹ å’Œå¾®è°ƒç¤ºä¾‹ã€‚æˆ‘ä»¬å°†åŠ è½½åœ¨ ImageNet ä¸Šé¢„è®­ç»ƒçš„ Xception æ¨¡å‹ï¼Œå¹¶å°†å…¶ç”¨äº Kaggle Dogs vs. Cats åˆ†ç±»æ•°æ®é›†ã€‚</p>
<p><a href="">ä»£ç </a></p>
<h3 id="è·å–æ•°æ®"><a href="#è·å–æ•°æ®" class="headerlink" title="è·å–æ•°æ®"></a>è·å–æ•°æ®</h3><p>é¦–å…ˆï¼Œæˆ‘ä»¬ä½¿ç”¨ TFDS æ¥è·å– Dogs vs. Cats æ•°æ®é›†ã€‚å¦‚æœæ‚¨æ‹¥æœ‰è‡ªå·±çš„æ•°æ®é›†ï¼Œåˆ™å¯èƒ½éœ€è¦ä½¿ç”¨æ•ˆç”¨å‡½æ•° <a href="https://tensorflow.google.cn/api_docs/python/tf/keras/utils/image_dataset_from_directory?hl=zh-cn"><code>tf.keras.preprocessing.image_dataset_from_directory</code></a> ä»ç£ç›˜ä¸Šå­˜æ¡£åˆ°ç±»ç‰¹å®šçš„æ–‡ä»¶å¤¹ä¸­çš„ä¸€ç»„å›¾åƒæ¥ç”Ÿæˆç›¸ä¼¼çš„æœ‰æ ‡ç­¾æ•°æ®é›†å¯¹è±¡ã€‚</p>
<p>ä½¿ç”¨éå¸¸å°çš„æ•°æ®é›†æ—¶ï¼Œè¿ç§»å­¦ä¹ æœ€å®ç”¨ã€‚ä¸ºäº†ä½¿æ•°æ®é›†ä¿æŒè¾ƒå°çŠ¶æ€ï¼Œæˆ‘ä»¬å°†åŸå§‹è®­ç»ƒæ•°æ®ï¼ˆ25,000 ä¸ªå›¾åƒï¼‰çš„ 40% ç”¨äºè®­ç»ƒï¼Œ10% ç”¨äºéªŒè¯ï¼Œ10% ç”¨äºæµ‹è¯•ã€‚</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow_datasets <span class="keyword">as</span> tfds</span><br><span class="line"></span><br><span class="line">tfds.disable_progress_bar()</span><br><span class="line"></span><br><span class="line">train_ds, validation_ds, test_ds = tfds.load(</span><br><span class="line">    <span class="string">&quot;cats_vs_dogs&quot;</span>,</span><br><span class="line">    <span class="comment"># Reserve 10% for validation and 10% for test</span></span><br><span class="line">    split=[<span class="string">&quot;train[:40%]&quot;</span>, <span class="string">&quot;train[40%:50%]&quot;</span>, <span class="string">&quot;train[50%:60%]&quot;</span>],</span><br><span class="line">    as_supervised=<span class="literal">True</span>,  <span class="comment"># Include labels</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Number of training samples: %d&quot;</span> % tf.data.experimental.cardinality(train_ds))</span><br><span class="line"><span class="built_in">print</span>(</span><br><span class="line">    <span class="string">&quot;Number of validation samples: %d&quot;</span> % tf.data.experimental.cardinality(validation_ds)</span><br><span class="line">)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Number of test samples: %d&quot;</span> % tf.data.experimental.cardinality(test_ds))</span><br></pre></td></tr></table></figure>

<p>ä¸‹é¢æ˜¯è®­ç»ƒæ•°æ®é›†ä¸­çš„å‰ 9 ä¸ªå›¾åƒã€‚å¦‚æ‚¨æ‰€è§ï¼Œå®ƒä»¬å…·æœ‰ä¸åŒçš„å¤§å°ã€‚</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>, <span class="number">10</span>))</span><br><span class="line"><span class="keyword">for</span> i, (image, label) <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_ds.take(<span class="number">9</span>)):</span><br><span class="line">    ax = plt.subplot(<span class="number">3</span>, <span class="number">3</span>, i + <span class="number">1</span>)</span><br><span class="line">    plt.imshow(image)</span><br><span class="line">    plt.title(<span class="built_in">int</span>(label))</span><br><span class="line">    plt.axis(<span class="string">&quot;off&quot;</span>)</span><br></pre></td></tr></table></figure>

<h3 id="æ ‡å‡†åŒ–æ•°æ®"><a href="#æ ‡å‡†åŒ–æ•°æ®" class="headerlink" title="æ ‡å‡†åŒ–æ•°æ®"></a>æ ‡å‡†åŒ–æ•°æ®</h3><p>æˆ‘ä»¬çš„åŸå§‹å›¾åƒæœ‰å„ç§å¤§å°ã€‚å¦å¤–ï¼Œæ¯ä¸ªåƒç´ ç”± 0 åˆ° 255 ä¹‹é—´çš„ 3 ä¸ªæ•´æ•°å€¼ï¼ˆRGB è‰²é˜¶å€¼ï¼‰ç»„æˆã€‚è¿™ä¸å¤ªé€‚åˆé¦ˆé€ç¥ç»ç½‘ç»œã€‚æˆ‘ä»¬éœ€è¦åšä¸‹é¢ä¸¤ä»¶äº‹ï¼š</p>
<ul>
<li><p>æ ‡å‡†åŒ–ä¸ºå›ºå®šå›¾åƒå¤§å°ã€‚æˆ‘ä»¬é€‰æ‹© 150x150ã€‚</p>
</li>
<li><p>åœ¨ -1 è‡³ 1 ä¹‹é—´å½’ä¸€åŒ–åƒç´ å€¼ã€‚æˆ‘ä»¬å°†ä½¿ç”¨ <code>Normalization</code> å±‚ä½œä¸ºæ¨¡å‹æœ¬èº«çš„ä¸€éƒ¨åˆ†æ¥è¿›è¡Œæ­¤æ“ä½œã€‚</p>
</li>
</ul>
<p>ä¸€èˆ¬è€Œè¨€ï¼Œä¸é‡‡ç”¨å·²é¢„å¤„ç†æ•°æ®çš„æ¨¡å‹ç›¸åï¼Œå¼€å‘ä»¥åŸå§‹æ•°æ®ä½œä¸ºè¾“å…¥çš„æ¨¡å‹æ˜¯ä¸€ç§è‰¯å¥½çš„åšæ³•ã€‚åŸå› åœ¨äºï¼Œå¦‚æœæ¨¡å‹éœ€è¦é¢„å¤„ç†çš„æ•°æ®ï¼Œåˆ™æ¯æ¬¡å¯¼å‡ºæ¨¡å‹ä»¥åœ¨å…¶ä»–åœ°æ–¹ï¼ˆåœ¨ç½‘ç»œæµè§ˆå™¨ã€ç§»åŠ¨åº”ç”¨ä¸­ï¼‰ä½¿ç”¨æ—¶ï¼Œéƒ½éœ€è¦é‡æ–°å®ç°å®Œå…¨ç›¸åŒçš„é¢„å¤„ç†æµæ°´çº¿ã€‚è¿™å¾ˆå¿«å°±ä¼šå˜å¾—éå¸¸æ£˜æ‰‹ã€‚å› æ­¤ï¼Œåœ¨å‘½ä¸­æ¨¡å‹ä¹‹å‰ï¼Œæˆ‘ä»¬åº”å½“å°½å¯èƒ½å°‘åœ°è¿›è¡Œé¢„å¤„ç†ã€‚</p>
<p>åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬å°†åœ¨æ•°æ®æµæ°´çº¿ä¸­è¿›è¡Œå›¾åƒå¤§å°è°ƒæ•´ï¼ˆå› ä¸ºæ·±åº¦ç¥ç»ç½‘ç»œåªèƒ½å¤„ç†è¿ç»­çš„æ•°æ®æ‰¹æ¬¡ï¼‰ï¼Œå¹¶åœ¨åˆ›å»ºæ¨¡å‹æ—¶å°†å…¶ä½œä¸ºæ¨¡å‹çš„ä¸€éƒ¨åˆ†è¿›è¡Œè¾“å…¥å€¼ç¼©æ”¾ã€‚</p>
<p>æˆ‘ä»¬å°†å›¾åƒçš„å¤§å°è°ƒæ•´ä¸º 150x150ï¼š</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">size = (<span class="number">150</span>, <span class="number">150</span>)</span><br><span class="line"></span><br><span class="line">train_ds = train_ds.<span class="built_in">map</span>(<span class="keyword">lambda</span> x, y: (tf.image.resize(x, size), y))</span><br><span class="line"><span class="comment"># map çš„è¾“å…¥æ˜¯ä¸€ä¸ªå‡½æ•°åï¼ˆå‡½æ•°åœ°å€ï¼‰</span></span><br><span class="line"><span class="comment"># lambda å‡½æ•°ï¼šè¾“å…¥ x å’Œ yï¼Œè¾“å‡º resize åçš„ x å’Œ y</span></span><br><span class="line">validation_ds = validation_ds.<span class="built_in">map</span>(<span class="keyword">lambda</span> x, y: (tf.image.resize(x, size), y))</span><br><span class="line">test_ds = test_ds.<span class="built_in">map</span>(<span class="keyword">lambda</span> x, y: (tf.image.resize(x, size), y))</span><br></pre></td></tr></table></figure>

<p>æ­¤å¤–ï¼Œæˆ‘ä»¬å¯¹æ•°æ®è¿›è¡Œæ‰¹å¤„ç†å¹¶ä½¿ç”¨ç¼“å­˜å’Œé¢„æå–æ¥ä¼˜åŒ–åŠ è½½é€Ÿåº¦ã€‚</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">batch_size = <span class="number">32</span></span><br><span class="line"></span><br><span class="line">train_ds = train_ds.cache().batch(batch_size).prefetch(buffer_size=<span class="number">10</span>)</span><br><span class="line">validation_ds = validation_ds.cache().batch(batch_size).prefetch(buffer_size=<span class="number">10</span>)</span><br><span class="line">test_ds = test_ds.cache().batch(batch_size).prefetch(buffer_size=<span class="number">10</span>)</span><br></pre></td></tr></table></figure>

<h3 id="ä½¿ç”¨éšæœºæ•°æ®æ‰©å……"><a href="#ä½¿ç”¨éšæœºæ•°æ®æ‰©å……" class="headerlink" title="ä½¿ç”¨éšæœºæ•°æ®æ‰©å……"></a>ä½¿ç”¨éšæœºæ•°æ®æ‰©å……</h3><p>å½“æ‚¨æ²¡æœ‰è¾ƒå¤§çš„å›¾åƒæ•°æ®é›†æ—¶ï¼Œé€šè¿‡å°†éšæœºä½†ç°å®çš„è½¬æ¢ï¼ˆä¾‹å¦‚éšæœºæ°´å¹³ç¿»è½¬æˆ–å°å¹…éšæœºæ—‹è½¬ï¼‰åº”ç”¨äºè®­ç»ƒå›¾åƒæ¥äººä¸ºå¼•å…¥æ ·æœ¬å¤šæ ·æ€§æ˜¯ä¸€ç§è‰¯å¥½çš„åšæ³•ã€‚è¿™æœ‰åŠ©äºä½¿æ¨¡å‹æš´éœ²äºè®­ç»ƒæ•°æ®çš„ä¸åŒæ–¹é¢ï¼ŒåŒæ—¶å‡æ…¢è¿‡æ‹Ÿåˆçš„é€Ÿåº¦ã€‚</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> layers</span><br><span class="line"></span><br><span class="line">data_augmentation = keras.Sequential(</span><br><span class="line">    [</span><br><span class="line">        layers.experimental.preprocessing.RandomFlip(<span class="string">&quot;horizontal&quot;</span>),</span><br><span class="line">        layers.experimental.preprocessing.RandomRotation(<span class="number">0.1</span>),</span><br><span class="line">    ]</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<p>æˆ‘ä»¬çœ‹ä¸€ä¸‹ç»è¿‡å„ç§éšæœºè½¬æ¢åç¬¬ä¸€ä¸ªæ‰¹æ¬¡çš„ç¬¬ä¸€ä¸ªå›¾åƒæ˜¯ä»€ä¹ˆæ ·ï¼š</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> images, labels <span class="keyword">in</span> train_ds.take(<span class="number">1</span>):</span><br><span class="line">    plt.figure(figsize=(<span class="number">10</span>, <span class="number">10</span>))</span><br><span class="line">    first_image = images[<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">9</span>):</span><br><span class="line">        ax = plt.subplot(<span class="number">3</span>, <span class="number">3</span>, i + <span class="number">1</span>)</span><br><span class="line">        augmented_image = data_augmentation(</span><br><span class="line">            tf.expand_dims(first_image, <span class="number">0</span>), training=<span class="literal">True</span></span><br><span class="line">        )</span><br><span class="line">        plt.imshow(augmented_image[<span class="number">0</span>].numpy().astype(<span class="string">&quot;int32&quot;</span>))</span><br><span class="line">        plt.title(<span class="built_in">int</span>(labels[<span class="number">0</span>]))</span><br><span class="line">        plt.axis(<span class="string">&quot;off&quot;</span>)</span><br></pre></td></tr></table></figure>

<h3 id="æ„å»ºæ¨¡å‹"><a href="#æ„å»ºæ¨¡å‹" class="headerlink" title="æ„å»ºæ¨¡å‹"></a>æ„å»ºæ¨¡å‹</h3><p>ç°åœ¨ï¼Œæˆ‘ä»¬æ¥æ„å»ºä¸€ä¸ªéµå¾ªæˆ‘ä»¬å…ˆå‰è§£é‡Šçš„è“å›¾çš„æ¨¡å‹ã€‚</p>
<p>æ³¨æ„ï¼š</p>
<ul>
<li><p>æˆ‘ä»¬æ·»åŠ  <code>Normalization</code> å±‚ä»¥å°†è¾“å…¥å€¼ï¼ˆæœ€åˆåœ¨ <code>[0, 255]</code> èŒƒå›´å†…ï¼‰ç¼©æ”¾åˆ° <code>[-1, 1]</code> èŒƒå›´ã€‚</p>
</li>
<li><p>æˆ‘ä»¬åœ¨åˆ†ç±»å±‚ä¹‹å‰æ·»åŠ ä¸€ä¸ª <code>Dropout</code> å±‚ï¼Œä»¥è¿›è¡Œæ­£åˆ™åŒ–ã€‚</p>
</li>
<li><p>æˆ‘ä»¬ç¡®ä¿åœ¨è°ƒç”¨åŸºç¡€æ¨¡å‹æ—¶ä¼ é€’ <code>training=False</code>ï¼Œä½¿å…¶åœ¨æ¨æ–­æ¨¡å¼ä¸‹è¿è¡Œï¼Œè¿™æ ·ï¼Œå³ä½¿åœ¨æˆ‘ä»¬è§£å†»åŸºç¡€æ¨¡å‹ä»¥è¿›è¡Œå¾®è°ƒåï¼Œbatchnorm ç»Ÿè®¡ä¿¡æ¯ä¹Ÿä¸ä¼šæ›´æ–°ã€‚</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">base_model = keras.applications.Xception(</span><br><span class="line">    weights=<span class="string">&quot;imagenet&quot;</span>,  <span class="comment"># Load weights pre-trained on ImageNet.</span></span><br><span class="line">    input_shape=(<span class="number">150</span>, <span class="number">150</span>, <span class="number">3</span>),</span><br><span class="line">    include_top=<span class="literal">False</span>,</span><br><span class="line">)  <span class="comment"># Do not include the ImageNet classifier at the top.</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Freeze the base_model</span></span><br><span class="line">base_model.trainable = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Create new model on top</span></span><br><span class="line">inputs = keras.Input(shape=(<span class="number">150</span>, <span class="number">150</span>, <span class="number">3</span>))</span><br><span class="line">x = data_augmentation(inputs)  <span class="comment"># Apply random data augmentation</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Pre-trained Xception weights requires that input be normalized</span></span><br><span class="line"><span class="comment"># from (0, 255) to a range (-1., +1.), the normalization layer</span></span><br><span class="line"><span class="comment"># does the following, outputs = (inputs - mean) / sqrt(var)</span></span><br><span class="line">norm_layer = keras.layers.experimental.preprocessing.Normalization()</span><br><span class="line">mean = np.array([<span class="number">127.5</span>] * <span class="number">3</span>)</span><br><span class="line">var = mean ** <span class="number">2</span></span><br><span class="line"><span class="comment"># Scale inputs to [-1, +1]</span></span><br><span class="line">x = norm_layer(x)</span><br><span class="line">norm_layer.set_weights([mean, var])</span><br><span class="line"></span><br><span class="line"><span class="comment"># The base model contains batchnorm layers. We want to keep them in inference mode</span></span><br><span class="line"><span class="comment"># when we unfreeze the base model for fine-tuning, so we make sure that the</span></span><br><span class="line"><span class="comment"># base_model is running in inference mode here.</span></span><br><span class="line">x = base_model(x, training=<span class="literal">False</span>)</span><br><span class="line">x = keras.layers.GlobalAveragePooling2D()(x)</span><br><span class="line">x = keras.layers.Dropout(<span class="number">0.2</span>)(x)  <span class="comment"># Regularize with dropout</span></span><br><span class="line">outputs = keras.layers.Dense(<span class="number">1</span>)(x)</span><br><span class="line">model = keras.Model(inputs, outputs)</span><br><span class="line"></span><br><span class="line">model.summary()</span><br></pre></td></tr></table></figure>

<h3 id="è®­ç»ƒé¡¶å±‚"><a href="#è®­ç»ƒé¡¶å±‚" class="headerlink" title="è®­ç»ƒé¡¶å±‚"></a>è®­ç»ƒé¡¶å±‚</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">model.compile(</span><br><span class="line">    optimizer=keras.optimizers.Adam(),</span><br><span class="line">    loss=keras.losses.BinaryCrossentropy(from_logits=True),</span><br><span class="line">    metrics=[keras.metrics.BinaryAccuracy()],</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">epochs = 20</span><br><span class="line">model.fit(train_ds, epochs=epochs, validation_data=validation_ds)</span><br></pre></td></tr></table></figure>

<h3 id="å¯¹æ•´ä¸ªæ¨¡å‹è¿›è¡Œä¸€è½®å¾®è°ƒ"><a href="#å¯¹æ•´ä¸ªæ¨¡å‹è¿›è¡Œä¸€è½®å¾®è°ƒ" class="headerlink" title="å¯¹æ•´ä¸ªæ¨¡å‹è¿›è¡Œä¸€è½®å¾®è°ƒ"></a>å¯¹æ•´ä¸ªæ¨¡å‹è¿›è¡Œä¸€è½®å¾®è°ƒ</h3><p>æœ€åï¼Œæˆ‘ä»¬è§£å†»åŸºç¡€æ¨¡å‹ï¼Œå¹¶ä»¥è¾ƒä½çš„å­¦ä¹ ç‡ç«¯åˆ°ç«¯åœ°è®­ç»ƒæ•´ä¸ªæ¨¡å‹ã€‚</p>
<p>é‡è¦çš„æ˜¯ï¼Œå°½ç®¡åŸºç¡€æ¨¡å‹å˜å¾—å¯è®­ç»ƒï¼Œä½†åœ¨æ„å»ºæ¨¡å‹è¿‡ç¨‹ä¸­ï¼Œç”±äºæˆ‘ä»¬åœ¨è°ƒç”¨è¯¥æ¨¡å‹æ—¶ä¼ é€’äº† <code>training=False</code>ï¼Œå› æ­¤å®ƒä»åœ¨æ¨æ–­æ¨¡å¼ä¸‹è¿è¡Œã€‚è¿™æ„å‘³ç€å†…éƒ¨çš„æ‰¹æ¬¡å½’ä¸€åŒ–å±‚ä¸ä¼šæ›´æ–°å…¶æ‰¹æ¬¡ç»Ÿè®¡ä¿¡æ¯ã€‚å¦‚æœå®ƒä»¬æ›´æ–°äº†è¿™äº›ç»Ÿè®¡ä¿¡æ¯ï¼Œåˆ™ä¼šç ´åè¯¥æ¨¡å‹åˆ°ç›®å‰ä¸ºæ­¢æ‰€å­¦ä¹ çš„è¡¨ç¤ºã€‚</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Unfreeze the base_model. Note that it keeps running in inference mode</span></span><br><span class="line"><span class="comment"># since we passed `training=False` when calling it. This means that</span></span><br><span class="line"><span class="comment"># the batchnorm layers will not update their batch statistics.</span></span><br><span class="line"><span class="comment"># This prevents the batchnorm layers from undoing all the training</span></span><br><span class="line"><span class="comment"># we&#x27;ve done so far.</span></span><br><span class="line">base_model.trainable = <span class="literal">True</span></span><br><span class="line">model.summary()</span><br><span class="line"></span><br><span class="line">model.<span class="built_in">compile</span>(</span><br><span class="line">    optimizer=keras.optimizers.Adam(<span class="number">1e-5</span>),  <span class="comment"># Low learning rate</span></span><br><span class="line">    loss=keras.losses.BinaryCrossentropy(from_logits=<span class="literal">True</span>),</span><br><span class="line">    metrics=[keras.metrics.BinaryAccuracy()],</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">epochs = <span class="number">10</span></span><br><span class="line">model.fit(train_ds, epochs=epochs, validation_data=validation_ds)</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>DeepLearning</category>
      </categories>
      <tags>
        <tag>TransferLearning</tag>
        <tag>DeepLearning</tag>
        <tag>keras</tag>
      </tags>
  </entry>
</search>
