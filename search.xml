<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>MarkDown 语法</title>
    <url>/blog/2021/11/28/MarkDown%20introduce/</url>
    <content><![CDATA[<h1 id="MarkDown-语法总结"><a href="#MarkDown-语法总结" class="headerlink" title="MarkDown 语法总结"></a>MarkDown 语法总结</h1><h2 id="换行"><a href="#换行" class="headerlink" title="换行"></a>换行</h2><ul>
<li><strong>markdown</strong> 中可以使用“空一行”来实现换行</li>
</ul>
<figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">Keras 有两个重要的概念： </span><br><span class="line"></span><br><span class="line">模型（Model）:</span><br><span class="line"></span><br><span class="line">层（Layer） :</span><br></pre></td></tr></table></figure>

<ul>
<li>可以使用 HTML &lt;br&gt; 换行</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Keras 有两个重要的概念：&lt;br&gt;</span><br><span class="line">模型（Model）: &lt;br&gt;</span><br><span class="line">层（Layer）:</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<span id="more"></span>

<h2 id="并列插入多幅图片"><a href="#并列插入多幅图片" class="headerlink" title="并列插入多幅图片"></a>并列插入多幅图片</h2><figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">align</span>=<span class="string">&quot;center&quot;</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">img</span> <span class="attr">src</span>=<span class="string">&quot;001.png&quot;</span> <span class="attr">height</span>=<span class="string">&quot;120&quot;</span> <span class="attr">width</span>=<span class="string">&quot;188&quot;</span> &gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">img</span> <span class="attr">src</span>=<span class="string">&quot;012.png&quot;</span> <span class="attr">height</span>=<span class="string">&quot;120&quot;</span> <span class="attr">width</span>=<span class="string">&quot;188&quot;</span> &gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">img</span> <span class="attr">src</span>=<span class="string">&quot;032.png&quot;</span> <span class="attr">height</span>=<span class="string">&quot;120&quot;</span> <span class="attr">width</span>=<span class="string">&quot;188&quot;</span> &gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h2 id="字体颜色"><a href="#字体颜色" class="headerlink" title="字体颜色"></a>字体颜色</h2><p>字体颜色：<font color=Blue>Test</font></p>
<p> <code>&lt;font color=Blue&gt;Test&lt;/font&gt;</code></p>
<p>背景颜色：<font style=background:red>Test</font></p>
<p><code>&lt;font style=background:red&gt;Test&lt;/font&gt;</code></p>
<h2 id="标题"><a href="#标题" class="headerlink" title="标题"></a>标题</h2><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line"><span class="section">#一级标题</span></span><br><span class="line"><span class="section">##二级标题</span></span><br><span class="line"><span class="section">###三级标题</span></span><br></pre></td></tr></table></figure>

<h2 id="列表"><a href="#列表" class="headerlink" title="列表"></a>列表</h2><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">无序列表：</span><br><span class="line"><span class="bullet">-</span> 列表1</span><br><span class="line"><span class="bullet">-</span> 列表2</span><br><span class="line"><span class="code">	a 子列表1</span></span><br><span class="line"><span class="code">	b 子列表2</span></span><br><span class="line"><span class="code"></span></span><br><span class="line">有序列表：</span><br><span class="line"><span class="bullet">1.</span> 列表1</span><br><span class="line"><span class="bullet">2.</span> 列表2</span><br></pre></td></tr></table></figure>

<h2 id="横线"><a href="#横线" class="headerlink" title="横线"></a>横线</h2><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">---</span><br><span class="line"></span><br><span class="line"><span class="strong">**<span class="emphasis">*</span></span></span><br></pre></td></tr></table></figure>

<h2 id="链接"><a href="#链接" class="headerlink" title="链接"></a>链接</h2><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">[<span class="string">网站名字</span>](<span class="link">url</span>)</span><br></pre></td></tr></table></figure>

<h2 id="插入图片"><a href="#插入图片" class="headerlink" title="插入图片"></a>插入图片</h2><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">![<span class="string">图片名字</span>](<span class="link">url</span>)</span><br></pre></td></tr></table></figure>

<h2 id="字体格式"><a href="#字体格式" class="headerlink" title="字体格式"></a>字体格式</h2><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">粗体：</span><br><span class="line"><span class="strong">**粗体**</span></span><br><span class="line">斜体：</span><br><span class="line"><span class="emphasis">*粗体*</span></span><br></pre></td></tr></table></figure>

<h2 id="代码块"><a href="#代码块" class="headerlink" title="代码块"></a>代码块</h2><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line"><span class="code">`hello, world!`</span></span><br><span class="line"></span><br><span class="line"><span class="code">```</span></span><br><span class="line"><span class="code">#include &lt;iostream&gt;</span></span><br><span class="line"><span class="code">using namespace std;</span></span><br><span class="line"><span class="code"></span></span><br><span class="line"><span class="code">int mian()&#123;</span></span><br><span class="line"><span class="code">    printf(&quot;hello, world!\n&quot;);</span></span><br><span class="line"><span class="code">    return 0;</span></span><br><span class="line"><span class="code">&#125;</span></span><br><span class="line"><span class="code">```</span></span><br></pre></td></tr></table></figure>

<h2 id="引用"><a href="#引用" class="headerlink" title="引用"></a>引用</h2><blockquote>
<p>引用效果！</p>
</blockquote>
<figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">&gt;引用效果！</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>MarkDown</category>
      </categories>
      <tags>
        <tag>MarkDown</tag>
      </tags>
  </entry>
  <entry>
    <title>Hello World</title>
    <url>/blog/2021/12/01/hello-world/</url>
    <content><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p>
<span id="more"></span>

<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>
]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title>project_architecture</title>
    <url>/blog/2021/12/07/project-architecture/</url>
    <content><![CDATA[<h1 id="DL-项目的组织架构"><a href="#DL-项目的组织架构" class="headerlink" title="DL 项目的组织架构"></a>DL 项目的组织架构</h1><span id="more"></span>

<p>项目结构如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># 建议使用文件夹，如果文件少的话，单个文件也是可以的</span></span><br><span class="line">ProjectDir:</span><br><span class="line">- dataDir</span><br><span class="line">	-- datafile (Cifar10)</span><br><span class="line">- modelsDir <span class="keyword">or</span> model.py  <span class="comment"># 存放模型文件</span></span><br><span class="line">	-- __init__.py (空文件即可)</span><br><span class="line">	-- VGG18.py</span><br><span class="line">	-- resnet18.py</span><br><span class="line">	-- resnet50.py</span><br><span class="line">- utilsDir <span class="keyword">or</span> utils.py  <span class="comment"># 存放一些工具文件</span></span><br><span class="line">	-- __init__.py</span><br><span class="line">	-- plots.py</span><br><span class="line">	-- loss.py</span><br><span class="line">	-- dataset.py</span><br><span class="line">	-- download.py</span><br><span class="line">- train.py (要包含validation的功能)  <span class="comment"># 训练文件</span></span><br><span class="line">- test.py <span class="keyword">or</span> <span class="built_in">eval</span>.py  <span class="comment"># 测试文件</span></span><br><span class="line">- README.md  <span class="comment"># 项目介绍文件</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">...... 下面这些还不太懂</span><br><span class="line">- detect.py</span><br><span class="line">- export.py</span><br><span class="line"></span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>Project Architecture</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>architecture</tag>
      </tags>
  </entry>
  <entry>
    <title>pip usage</title>
    <url>/blog/2021/12/11/pip-usage/pip-usage/</url>
    <content><![CDATA[<h1 id="Pip-Usage"><a href="#Pip-Usage" class="headerlink" title="Pip Usage"></a>Pip Usage</h1><h2 id="pip-基本语法😉"><a href="#pip-基本语法😉" class="headerlink" title="pip 基本语法😉"></a>pip 基本语法😉</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">pip install SomePackage            # latest version</span><br><span class="line">pip install SomePackage==1.0.4     # specific version</span><br><span class="line">pip install &#x27;SomePackage&gt;=1.0.4&#x27;   # minimum version</span><br></pre></td></tr></table></figure>

<span id="more"></span>

<h2 id="pip-高级用法👍"><a href="#pip-高级用法👍" class="headerlink" title="pip 高级用法👍"></a>pip 高级用法👍</h2><p>编写 package 版本文件 <code>requirements.txt</code> (●’◡’●)</p>
<h3 id="当前已装库-list"><a href="#当前已装库-list" class="headerlink" title="当前已装库 list"></a>当前已装库 list</h3><p><code>pip freeze</code> 可以实现：获得项目运行时，所需安装库的固定版本</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">pip freeze &gt; requirements.txt</span><br></pre></td></tr></table></figure>

<p>运行该语句后，在项目目录会出现 <code>requirements.txt</code> 其中包含环境中的各种 <code>package</code></p>
<h3 id="安装语法🎶"><a href="#安装语法🎶" class="headerlink" title="安装语法🎶"></a>安装语法🎶</h3><p><code>pip install -r</code> 将会自动安装 <code>requirements.txt</code> 中的所有 <code>package</code></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">pip install -r requirements.txt</span><br></pre></td></tr></table></figure>

<h3 id="requirements-txt-结构"><a href="#requirements-txt-结构" class="headerlink" title="requirements.txt 结构"></a>requirements.txt 结构</h3><ul>
<li><p>Comments：A line that begins with <code>#</code> is treated as a comment and ignored.</p>
</li>
<li><p>Encoding：Requirements files are <code>utf-8</code> encoding by default</p>
</li>
<li><p>Line continuations（续行）：A line ending in an unescaped <code>\</code> is treated as a line continuation</p>
</li>
</ul>
<h3 id="requirements-txt-例"><a href="#requirements-txt-例" class="headerlink" title="requirements.txt 例"></a>requirements.txt 例</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">###### Requirements with Version Specifiers ######</span></span><br><span class="line"><span class="comment">#   See https://www.python.org/dev/peps/pep-0440/#version-specifiers</span></span><br><span class="line">docopt == <span class="number">0.6</span><span class="number">.1</span>             <span class="comment"># Version Matching. Must be version 0.6.1</span></span><br><span class="line">keyring &gt;= <span class="number">4.1</span><span class="number">.1</span>            <span class="comment"># Minimum version 4.1.1</span></span><br><span class="line">coverage != <span class="number">3.5</span>             <span class="comment"># Version Exclusion. Anything except version 3.5</span></span><br><span class="line">Mopidy-Dirble ~= <span class="number">1.1</span>        <span class="comment"># Compatible release. Same as &gt;= 1.1, == 1.*</span></span><br></pre></td></tr></table></figure>

<p><a href="https://github.com/ultralytics/yolov5/blob/master/requirements.txt">一个例子</a></p>
]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>pip</tag>
      </tags>
  </entry>
  <entry>
    <title>pyYAML Usage</title>
    <url>/blog/2021/12/11/pyYAML/pyYAML/</url>
    <content><![CDATA[<h1 id="pyYAML-Usage"><a href="#pyYAML-Usage" class="headerlink" title="pyYAML Usage"></a>pyYAML Usage</h1><p>使用 yaml 文件配置模型以及训练参数，方便调参数！😉</p>
<p>借鉴文章：<a href="https://zhuanlan.zhihu.com/p/42678768">https://zhuanlan.zhihu.com/p/42678768</a></p>
<span id="more"></span>

<h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">pip install PyYAML</span><br></pre></td></tr></table></figure>

<h2 id="YAML-基本语法"><a href="#YAML-基本语法" class="headerlink" title="YAML 基本语法"></a>YAML 基本语法</h2><ul>
<li><p>与Python一样采用缩进区分层级，需要同一层级文件缩进相同，但是不能用TAB，只能使用空格；</p>
</li>
<li><p><code>#</code> 表示注释，从它开始到行尾都被忽略；</p>
</li>
<li><p>大小写敏感；</p>
</li>
<li><p> <code>-</code> 开头，整个文件会被转换为list，其中 <code>-</code> 后的内容属于一个字典；</p>
</li>
<li><p><code>:</code> 前后的内容转换为 dictionary 的键值对；</p>
</li>
<li><p>单引号内的内容按照字符串输出，不会变成转移字符，双引号内内容存在转义字符会转换</p>
</li>
</ul>
<h3 id="list"><a href="#list" class="headerlink" title="list"></a>list</h3><blockquote>
<p>parameters.yaml 内容 &amp; .py：</p>
</blockquote>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># exchange to list</span></span><br><span class="line"><span class="bullet">-</span> <span class="string">a</span></span><br><span class="line"><span class="bullet">-</span> <span class="string">b</span></span><br><span class="line"><span class="bullet">-</span> <span class="string">c</span></span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> yaml</span><br><span class="line"><span class="keyword">from</span> yaml <span class="keyword">import</span> CLoader <span class="keyword">as</span> Loader</span><br><span class="line"></span><br><span class="line">f = <span class="built_in">open</span>(<span class="string">&#x27;parameters.yml&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line">para = yaml.load(f, Loader)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>(para))</span><br><span class="line"><span class="built_in">print</span>(para)</span><br></pre></td></tr></table></figure>

<p>输出：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">&lt;class &#x27;list&#x27;&gt;</span><br><span class="line">[&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;]</span><br></pre></td></tr></table></figure>

<h3 id="dictionary"><a href="#dictionary" class="headerlink" title="dictionary"></a>dictionary</h3><blockquote>
<p>.yml &amp; .py</p>
</blockquote>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># exchange to dictionary</span></span><br><span class="line"><span class="attr">name:</span> <span class="string">zhangsan</span></span><br><span class="line"><span class="attr">age:</span> <span class="number">30</span></span><br><span class="line"><span class="attr">nation:</span> <span class="string">China</span></span><br></pre></td></tr></table></figure>

<p>输出：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">&lt;class &#x27;dict&#x27;&gt;</span><br><span class="line">&#123;&#x27;name&#x27;: &#x27;zhangsan&#x27;, &#x27;age&#x27;: 30, &#x27;nation&#x27;: &#x27;China&#x27;&#125;</span><br></pre></td></tr></table></figure>

<h3 id="混合转换"><a href="#混合转换" class="headerlink" title="混合转换"></a>混合转换</h3><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># exchange to dictionary</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">zhangsan</span></span><br><span class="line">  <span class="attr">age:</span> <span class="number">30</span></span><br><span class="line">  <span class="attr">nation:</span> <span class="string">China</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">lisi</span></span><br><span class="line">  <span class="attr">age:</span> <span class="number">20</span></span><br><span class="line">  <span class="attr">nation:</span> <span class="string">China</span></span><br></pre></td></tr></table></figure>

<p>输出：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">&lt;class &#x27;list&#x27;&gt;</span><br><span class="line">[&#123;&#x27;name&#x27;: &#x27;zhangsan&#x27;, &#x27;age&#x27;: 30, &#x27;nation&#x27;: &#x27;China&#x27;&#125;,</span><br><span class="line"> &#123;&#x27;name&#x27;: &#x27;lisi&#x27;, &#x27;age&#x27;: 20, &#x27;nation&#x27;: &#x27;China&#x27;&#125;]</span><br></pre></td></tr></table></figure>

<h2 id="pyYAML-Usage-1"><a href="#pyYAML-Usage-1" class="headerlink" title="pyYAML Usage"></a>pyYAML Usage</h2><h3 id="import-package"><a href="#import-package" class="headerlink" title="import package"></a>import package</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> yaml  <span class="comment"># import this package</span></span><br></pre></td></tr></table></figure>

<h3 id="load"><a href="#load" class="headerlink" title="load()"></a>load()</h3><blockquote>
<p>加载 yaml 文件，返回一个 pyYAML 对象，这个对象是一个包含了键值对的 <code>list</code> 或 <code>dict</code></p>
</blockquote>
<p>我们一般使用 <code>load()</code> 就够了</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> yaml</span><br><span class="line"><span class="keyword">from</span> yaml <span class="keyword">import</span> CLoader <span class="keyword">as</span> Loader</span><br><span class="line"></span><br><span class="line">f = <span class="built_in">open</span>(<span class="string">&#x27;parameters.yml&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line">para = yaml.load(f, Loader)</span><br><span class="line">total_epoch = para[<span class="string">&#x27;total_epochs&#x27;</span>]</span><br><span class="line">batch_size = para[<span class="string">&#x27;batch_size&#x27;</span>]</span><br><span class="line">learning_rate = <span class="built_in">float</span>(para[<span class="string">&#x27;lr&#x27;</span>])</span><br><span class="line">target_acc = para[<span class="string">&#x27;target_acc&#x27;</span>]</span><br><span class="line">model_name = para[<span class="string">&#x27;model&#x27;</span>]</span><br><span class="line">dataset = para[<span class="string">&#x27;dataset&#x27;</span>]</span><br></pre></td></tr></table></figure>

<h3 id="dump"><a href="#dump" class="headerlink" title="dump()"></a>dump()</h3><blockquote>
<p>将键值对，转换成 yaml 格式</p>
</blockquote>
]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>YAML</tag>
      </tags>
  </entry>
  <entry>
    <title>Transfer Learning</title>
    <url>/blog/2021/12/25/%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0/1.0%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0/</url>
    <content><![CDATA[<h1 id="迁移学习和微调（keras）"><a href="#迁移学习和微调（keras）" class="headerlink" title="迁移学习和微调（keras）"></a>迁移学习和微调（keras）</h1><span id="more"></span>

<h2 id="import-setting"><a href="#import-setting" class="headerlink" title="import setting!"></a><strong>import setting!</strong></h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras</span><br></pre></td></tr></table></figure>

<h2 id="introduce"><a href="#introduce" class="headerlink" title="introduce"></a>introduce</h2><p><strong>迁移学习</strong>包括获取从一个问题中学习到的特征，然后将这些特征用于新的类似问题。例如，来自已学会识别浣熊的模型的特征可能对建立旨在识别狸猫的模型十分有用。</p>
<p>对于数据集中的数据太少而无法从头开始训练完整模型的任务，通常会执行迁移学习</p>
<p>在深度学习情境中，迁移学习最常见的形式是以下工作流：</p>
<ul>
<li><p>从之前训练的模型中获取层。</p>
</li>
<li><p>冻结这些层，以避免在后续训练轮次中破坏它们包含的任何信息。</p>
</li>
<li><p>在已冻结层的<strong>顶部</strong>添加一些新的可训练层。这些层会学习将旧特征转换为对新数据集的预测。</p>
</li>
<li><p>在您的数据集上训练新层。</p>
</li>
</ul>
<p>最后一个可选步骤是<strong>微调</strong>，包括解冻上面获得的整个模型（或模型的一部分），然后在新数据上以<strong>极低的学习率</strong>对该模型进行重新训练。以增量方式使预训练特征适应新数据，有可能实现有意义的改进。</p>
<p>首先，我们将详细介绍 Keras <code>trainable</code> API，它是大多数迁移学习和微调工作流的基础。</p>
<p>随后，我们将演示一个典型工作流：先获得一个在 ImageNet 数据集上预训练的模型，然后在 Kaggle Dogs vs. Cats 分类数据集上对该模型进行重新训练。</p>
<h2 id="冻结层：了解-trainable-特性"><a href="#冻结层：了解-trainable-特性" class="headerlink" title="冻结层：了解 trainable 特性"></a>冻结层：了解 <code>trainable</code> 特性</h2><p>层和模型具有三个权重特性：</p>
<ul>
<li><p><code>weights</code> 是层的所有权重变量的列表。</p>
</li>
<li><p><code>trainable_weights</code> 是需要进行更新（通过梯度下降）以尽可能减少训练过程中损失的权重列表。</p>
</li>
<li><p><code>non_trainable_weights</code> 是不适合训练的权重列表。它们通常在正向传递过程中由模型更新。</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">layer = keras.layers.Dense(<span class="number">3</span>)</span><br><span class="line">layer.build((<span class="literal">None</span>, <span class="number">4</span>))  <span class="comment"># Create the weights (build()&#x27;s paras: input_sahpe)</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;weights:&quot;</span>, <span class="built_in">len</span>(layer.weights))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;trainable_weights:&quot;</span>, <span class="built_in">len</span>(layer.trainable_weights))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;non_trainable_weights:&quot;</span>, <span class="built_in">len</span>(layer.non_trainable_weights))</span><br><span class="line"></span><br><span class="line"><span class="comment"># output</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">weights: 2</span></span><br><span class="line"><span class="string">trainable_weights: 2</span></span><br><span class="line"><span class="string">non_trainable_weights: 0</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>

<p>一般而言，所有权重都是可训练权重。唯一具有不可训练权重的内置层是 <code>BatchNormalization</code> 层。在训练期间，它使用不可训练权重跟踪其输入的平均值和方差。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">layer = keras.layers.BatchNormalization()</span><br><span class="line">layer.build((<span class="literal">None</span>, <span class="number">4</span>))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;weights:&quot;</span>, <span class="built_in">len</span>(layer.weights))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;trainable_weights:&quot;</span>, <span class="built_in">len</span>(layer.trainable_weights))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;non_trainable_weights:&quot;</span>, <span class="built_in">len</span>(layer.non_trainable_weights))</span><br><span class="line"></span><br><span class="line"><span class="comment"># output</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">weights: 4</span></span><br><span class="line"><span class="string">trainable_weights: 2</span></span><br><span class="line"><span class="string">non_trainable_weights: 2</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>

<p>层和模型还具有布尔特性 <code>trainable</code>💥。此特性的值可以更改。将 <code>layer.trainable</code> 设置为 <code>False</code> 会将层的所有权重从可训练移至不可训练。这一过程称为“冻结”层：已冻结层的状态在训练期间不会更新（无论是使用 <code>fit()</code> 进行训练，还是使用依赖于 <code>trainable_weights</code> 来应用梯度更新的任何自定义循环进行训练时）。</p>
<h3 id="示例：将-trainable-设置为-False"><a href="#示例：将-trainable-设置为-False" class="headerlink" title="示例：将 trainable 设置为 False"></a><strong>示例：将 <code>trainable</code> 设置为 <code>False</code></strong></h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">layer = keras.layers.Dense(<span class="number">3</span>)</span><br><span class="line">layer.build((<span class="literal">None</span>, <span class="number">4</span>))</span><br><span class="line">layer.trainable = <span class="literal">False</span>  <span class="comment"># Freeze the layer</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;weights:&quot;</span>, <span class="built_in">len</span>(layer.weights))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;trainable_weights:&quot;</span>, <span class="built_in">len</span>(layer.trainable_weights))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;non_trainable_weights:&quot;</span>, <span class="built_in">len</span>(layer.non_trainable_weights))</span><br><span class="line"><span class="comment"># output</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">weights: 2</span></span><br><span class="line"><span class="string">trainable_weights: 0</span></span><br><span class="line"><span class="string">non_trainable_weights: 2</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>

<p><strong>当可训练权重变为不可训练时，它的值在训练期间不再更新。</strong>👏</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Make a model with 2 layers</span></span><br><span class="line">layer1 = keras.layers.Dense(<span class="number">3</span>, activation=<span class="string">&quot;relu&quot;</span>)</span><br><span class="line">layer2 = keras.layers.Dense(<span class="number">3</span>, activation=<span class="string">&quot;sigmoid&quot;</span>)</span><br><span class="line">model = keras.Sequential([keras.Input(shape=(<span class="number">3</span>,)), layer1, layer2])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Freeze the first layer</span></span><br><span class="line">layer1.trainable = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Keep a copy of the weights of layer1 for later reference</span></span><br><span class="line">initial_layer1_weights_values = layer1.get_weights()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Train the model</span></span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=<span class="string">&quot;adam&quot;</span>, loss=<span class="string">&quot;mse&quot;</span>)</span><br><span class="line">model.fit(np.random.random((<span class="number">2</span>, <span class="number">3</span>)), np.random.random((<span class="number">2</span>, <span class="number">3</span>)))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Check that the weights of layer1 have not changed during training</span></span><br><span class="line">final_layer1_weights_values = layer1.get_weights()</span><br><span class="line">np.testing.assert_allclose(</span><br><span class="line">    initial_layer1_weights_values[<span class="number">0</span>], final_layer1_weights_values[<span class="number">0</span>]</span><br><span class="line">)</span><br><span class="line">np.testing.assert_allclose(</span><br><span class="line">    initial_layer1_weights_values[<span class="number">1</span>], final_layer1_weights_values[<span class="number">1</span>]</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># output</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">1/1 [==============================] - 1s 615ms/step - loss: 0.0895</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>

<p>请勿将 <code>layer.trainable</code> 特性与 <code>layer.__call__()</code> 中的 <code>training</code> 参数（此参数控制层是在推断模式还是训练模式下运行其前向传递）混淆。</p>
<h3 id="trainable-特性的递归设置"><a href="#trainable-特性的递归设置" class="headerlink" title="trainable 特性的递归设置"></a><code>trainable</code> 特性的递归设置</h3><p>如果在模型或具有子层的任何层上设置 <code>trainable = False</code>，则所有子层也将变为不可训练。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">inner_model = keras.Sequential(</span><br><span class="line">    [</span><br><span class="line">        keras.Input(shape=(<span class="number">3</span>,)),</span><br><span class="line">        keras.layers.Dense(<span class="number">3</span>, activation=<span class="string">&quot;relu&quot;</span>),</span><br><span class="line">        keras.layers.Dense(<span class="number">3</span>, activation=<span class="string">&quot;relu&quot;</span>),</span><br><span class="line">    ]</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">model = keras.Sequential(</span><br><span class="line">    [keras.Input(shape=(<span class="number">3</span>,)), inner_model, keras.layers.Dense(<span class="number">3</span>, activation=<span class="string">&quot;sigmoid&quot;</span>),]</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">model.trainable = <span class="literal">False</span>  <span class="comment"># Freeze the outer model</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">assert</span> inner_model.trainable == <span class="literal">False</span>  <span class="comment"># All layers in `model` are now frozen</span></span><br><span class="line"><span class="keyword">assert</span> inner_model.layers[<span class="number">0</span>].trainable == <span class="literal">False</span>  <span class="comment"># `trainable` is propagated recursively</span></span><br></pre></td></tr></table></figure>

<h2 id="典型的迁移学习工作流"><a href="#典型的迁移学习工作流" class="headerlink" title="典型的迁移学习工作流"></a>典型的迁移学习工作流</h2><p>下面将介绍如何在 Keras 中实现典型的迁移学习工作流👏：</p>
<ul>
<li><p>实例化一个基础模型并加载预训练权重。</p>
</li>
<li><p>通过设置 <code>trainable = False</code> 冻结基础模型中的所有层。</p>
</li>
<li><p>根据基础模型中一个（或多个）层的输出创建一个新模型。</p>
</li>
<li><p>在您的新数据集上训练新模型。</p>
</li>
</ul>
<p>请注意，另一种更轻量的工作流如下😊：</p>
<ul>
<li><p>实例化一个基础模型并加载预训练权重。</p>
</li>
<li><p>通过该模型运行新的数据集，并记录基础模型中一个（或多个）层的输出。这一过程称为<strong>特征提取</strong>。</p>
</li>
<li><p>使用该输出作为新的较小模型的输入数据。</p>
</li>
</ul>
<p>第二种工作流有一个关键优势，即您只需在自己的数据上运行一次基础模型，而不是每个训练周期都运行一次。因此，它的速度更快，开销也更低。</p>
<p>但是，第二种工作流存在一个问题，即它不允许您在训练期间动态修改新模型的输入数据，在进行数据扩充时，这种修改必不可少。当新数据集的数据太少而无法从头开始训练完整模型时，任务通常会使用迁移学习，在这种情况下，数据扩充非常重要。因此，在接下来的篇幅中，我们将专注于第一种工作流。</p>
<p>下面是 Keras 中第一种工作流的样子：</p>
<ol>
<li>首先，实例化一个具有预训练权重的基础模型。</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">base_model = keras.applications.Xception(</span><br><span class="line">    weights=<span class="string">&#x27;imagenet&#x27;</span>,  <span class="comment"># Load weights pre-trained on ImageNet.</span></span><br><span class="line">    input_shape=(<span class="number">150</span>, <span class="number">150</span>, <span class="number">3</span>),</span><br><span class="line">    include_top=<span class="literal">False</span>)  <span class="comment"># Do not include the ImageNet classifier at the top.</span></span><br></pre></td></tr></table></figure>

<ol start="2">
<li>随后，冻结该基础模型。</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">base_model.trainable = <span class="literal">False</span></span><br></pre></td></tr></table></figure>

<ol start="3">
<li>根据基础模型创建一个新模型。</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">inputs = keras.Input(shape=(<span class="number">150</span>, <span class="number">150</span>, <span class="number">3</span>))</span><br><span class="line"><span class="comment"># We make sure that the base_model is running in inference mode here,</span></span><br><span class="line"><span class="comment"># by passing `training=False`. This is important for fine-tuning, as you will</span></span><br><span class="line"><span class="comment"># learn in a few paragraphs.</span></span><br><span class="line">x = base_model(inputs, training=<span class="literal">False</span>)</span><br><span class="line"><span class="comment"># Convert features of shape `base_model.output_shape[1:]` to vectors</span></span><br><span class="line">x = keras.layers.GlobalAveragePooling2D()(x)</span><br><span class="line"><span class="comment"># A Dense classifier with a single unit (binary classification)</span></span><br><span class="line">outputs = keras.layers.Dense(<span class="number">1</span>)(x)</span><br><span class="line">model = keras.Model(inputs, outputs)</span><br></pre></td></tr></table></figure>

<ol start="4">
<li>在新数据上训练该模型。</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model.<span class="built_in">compile</span>(optimizer=keras.optimizers.Adam(),</span><br><span class="line">              loss=keras.losses.BinaryCrossentropy(from_logits=<span class="literal">True</span>),</span><br><span class="line">              metrics=[keras.metrics.BinaryAccuracy()])</span><br><span class="line">model.fit(new_dataset, epochs=<span class="number">20</span>, callbacks=..., validation_data=...)</span><br></pre></td></tr></table></figure>

<h2 id="微调"><a href="#微调" class="headerlink" title="微调"></a>微调</h2><p>一旦模型在新数据上收敛，您就可以尝试解冻全部或部分基础模型，并以<strong>极低的学习率</strong>端到端地重新训练整个模型。</p>
<p>这是可选的最后一个步骤，可能给您带来增量式改进。不过，它也可能导致<strong>快速过拟合</strong>，请牢记这一点。</p>
<p>重要的是，只有在将具有冻结层的模型训练至收敛<em>后</em>，才能执行此步骤。如果将随机初始化的可训练层与包含预训练特征的可训练层混合使用，则随机初始化的层将在训练过程中引起非常大的梯度更新，而这将破坏您的预训练特征。</p>
<p>在此阶段使用极低的学习率也很重要，因为与第一轮训练相比，您正在一个通常非常小的数据集上训练一个大得多的模型。因此，如果您应用较大的权重更新，则存在很快过拟合的风险。在这里，您只需要以增量方式重新调整预训练权重。</p>
<p>下面是实现整个基础模型微调的方法：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Unfreeze the base model</span></span><br><span class="line">base_model.trainable = <span class="literal">True</span>  <span class="comment"># 先把模型解冻！！！</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># It&#x27;s important to recompile your model after you make any changes</span></span><br><span class="line"><span class="comment"># to the `trainable` attribute of any inner layer, so that your changes</span></span><br><span class="line"><span class="comment"># are take into account</span></span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=keras.optimizers.Adam(<span class="number">1e-5</span>),  <span class="comment"># Very low learning rate</span></span><br><span class="line">              loss=keras.losses.BinaryCrossentropy(from_logits=<span class="literal">True</span>),</span><br><span class="line">              metrics=[keras.metrics.BinaryAccuracy()])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Train end-to-end. Be careful to stop before you overfit!</span></span><br><span class="line">model.fit(new_dataset, epochs=<span class="number">10</span>, callbacks=..., validation_data=...)</span><br></pre></td></tr></table></figure>

<p><strong>关于 <code>compile()</code> 和 <code>trainable</code> 的重要说明</strong></p>
<p>在模型上调用 <code>compile()</code> 是为了“冻结”该模型的行为。这意味着在编译模型时，应当在该模型的整个生命周期中保留 <code>trainable</code> 特性值，直到再次调用 <code>compile</code> 为止。因此，如果您更改了任何 <code>trainable</code> 值，请确保在模型上再次调用 <code>compile()</code>，将这些变更考虑在内。</p>
<p><strong>关于 <code>BatchNormalization</code> 层的重要说明</strong></p>
<p>许多图像模型都包含 <code>BatchNormalization</code> 层。在各种能想到的数量上，该层都是一个特例。需要牢记以下几点。</p>
<ul>
<li><code>BatchNormalization</code> 包含 2 个会在训练过程中更新的不可训练权重。它们是跟踪输入的平均值和方差的变量。</li>
<li>设置 <code>bn_layer.trainable = False</code> 时，<code>BatchNormalization</code> 层将以推断模式运行，并且不会更新其均值和方差统计信息。其他层一般不是这种情况，因为<a href="https://keras.io/getting_started/faq/#whats-the-difference-between-the-training-argument-in-call-and-the-trainable-attribute">权重可训练性和推断/训练模式是两个正交的概念</a>。但是对于 <code>BatchNormalization</code> 层，两者是绑定的。</li>
<li>解冻包含 <code>BatchNormalization</code> 层的模型以进行微调时，应在调用基础模型时通过传递 <code>training=False</code> 来使 <code>BatchNormalization</code> 层保持在推断模式下。否则，应用于不可训练权重的更新将突然破坏模型学习到的内容。</li>
</ul>
<p>您将在本指南结尾处的端到端示例中看到这种模式的实际运行。</p>
<h2 id="使用自定义训练循环进行迁移学习和微调"><a href="#使用自定义训练循环进行迁移学习和微调" class="headerlink" title="使用自定义训练循环进行迁移学习和微调"></a>使用自定义训练循环进行迁移学习和微调</h2><p>如果您使用的是自己的低级训练循环，而不是 <code>fit()</code>，则工作流基本保持不变。在应用梯度更新时，您应当注意仅考虑列表 <code>model.trainable_weights</code>：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Create base model</span></span><br><span class="line">base_model = keras.applications.Xception(</span><br><span class="line">    weights=<span class="string">&#x27;imagenet&#x27;</span>,</span><br><span class="line">    input_shape=(<span class="number">150</span>, <span class="number">150</span>, <span class="number">3</span>),</span><br><span class="line">    include_top=<span class="literal">False</span>)</span><br><span class="line"><span class="comment"># Freeze base model</span></span><br><span class="line">base_model.trainable = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Create new model on top.</span></span><br><span class="line">inputs = keras.Input(shape=(<span class="number">150</span>, <span class="number">150</span>, <span class="number">3</span>))</span><br><span class="line">x = base_model(inputs, training=<span class="literal">False</span>)</span><br><span class="line">x = keras.layers.GlobalAveragePooling2D()(x)</span><br><span class="line">outputs = keras.layers.Dense(<span class="number">1</span>)(x)</span><br><span class="line">model = keras.Model(inputs, outputs)</span><br><span class="line"></span><br><span class="line">loss_fn = keras.losses.BinaryCrossentropy(from_logits=<span class="literal">True</span>)</span><br><span class="line">optimizer = keras.optimizers.Adam()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Iterate over the batches of a dataset.</span></span><br><span class="line"><span class="keyword">for</span> inputs, targets <span class="keyword">in</span> new_dataset:</span><br><span class="line">    <span class="comment"># Open a GradientTape.</span></span><br><span class="line">	<span class="keyword">with</span> tf.GradientTape() <span class="keyword">as</span> tape:</span><br><span class="line">        <span class="comment"># Forward pass.</span></span><br><span class="line">        predictions = model(inputs)</span><br><span class="line">        <span class="comment"># Compute the loss value for this batch.</span></span><br><span class="line">        loss_value = loss_fn(targets, predictions)</span><br><span class="line">    <span class="comment"># Get gradients of loss wrt the *trainable* weights.</span></span><br><span class="line">    gradients = tape.gradient(loss_value, model.trainable_weights)</span><br><span class="line">    <span class="comment"># Update the weights of the model.</span></span><br><span class="line">    optimizer.apply_gradients(<span class="built_in">zip</span>(gradients, model.trainable_weights))   </span><br></pre></td></tr></table></figure>

<p>对于微调同样如此。</p>
<h2 id="端到端示例：基于-Dogs-vs-Cats-数据集微调图像分类模型"><a href="#端到端示例：基于-Dogs-vs-Cats-数据集微调图像分类模型" class="headerlink" title="端到端示例：基于 Dogs vs. Cats 数据集微调图像分类模型"></a>端到端示例：基于 Dogs vs. Cats 数据集微调图像分类模型</h2><p>为了巩固这些概念，我们先介绍一个具体的端到端迁移学习和微调示例。我们将加载在 ImageNet 上预训练的 Xception 模型，并将其用于 Kaggle Dogs vs. Cats 分类数据集。</p>
<p><a href="">代码</a></p>
<h3 id="获取数据"><a href="#获取数据" class="headerlink" title="获取数据"></a>获取数据</h3><p>首先，我们使用 TFDS 来获取 Dogs vs. Cats 数据集。如果您拥有自己的数据集，则可能需要使用效用函数 <a href="https://tensorflow.google.cn/api_docs/python/tf/keras/utils/image_dataset_from_directory?hl=zh-cn"><code>tf.keras.preprocessing.image_dataset_from_directory</code></a> 从磁盘上存档到类特定的文件夹中的一组图像来生成相似的有标签数据集对象。</p>
<p>使用非常小的数据集时，迁移学习最实用。为了使数据集保持较小状态，我们将原始训练数据（25,000 个图像）的 40% 用于训练，10% 用于验证，10% 用于测试。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow_datasets <span class="keyword">as</span> tfds</span><br><span class="line"></span><br><span class="line">tfds.disable_progress_bar()</span><br><span class="line"></span><br><span class="line">train_ds, validation_ds, test_ds = tfds.load(</span><br><span class="line">    <span class="string">&quot;cats_vs_dogs&quot;</span>,</span><br><span class="line">    <span class="comment"># Reserve 10% for validation and 10% for test</span></span><br><span class="line">    split=[<span class="string">&quot;train[:40%]&quot;</span>, <span class="string">&quot;train[40%:50%]&quot;</span>, <span class="string">&quot;train[50%:60%]&quot;</span>],</span><br><span class="line">    as_supervised=<span class="literal">True</span>,  <span class="comment"># Include labels</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Number of training samples: %d&quot;</span> % tf.data.experimental.cardinality(train_ds))</span><br><span class="line"><span class="built_in">print</span>(</span><br><span class="line">    <span class="string">&quot;Number of validation samples: %d&quot;</span> % tf.data.experimental.cardinality(validation_ds)</span><br><span class="line">)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Number of test samples: %d&quot;</span> % tf.data.experimental.cardinality(test_ds))</span><br></pre></td></tr></table></figure>

<p>下面是训练数据集中的前 9 个图像。如您所见，它们具有不同的大小。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>, <span class="number">10</span>))</span><br><span class="line"><span class="keyword">for</span> i, (image, label) <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_ds.take(<span class="number">9</span>)):</span><br><span class="line">    ax = plt.subplot(<span class="number">3</span>, <span class="number">3</span>, i + <span class="number">1</span>)</span><br><span class="line">    plt.imshow(image)</span><br><span class="line">    plt.title(<span class="built_in">int</span>(label))</span><br><span class="line">    plt.axis(<span class="string">&quot;off&quot;</span>)</span><br></pre></td></tr></table></figure>

<h3 id="标准化数据"><a href="#标准化数据" class="headerlink" title="标准化数据"></a>标准化数据</h3><p>我们的原始图像有各种大小。另外，每个像素由 0 到 255 之间的 3 个整数值（RGB 色阶值）组成。这不太适合馈送神经网络。我们需要做下面两件事：</p>
<ul>
<li><p>标准化为固定图像大小。我们选择 150x150。</p>
</li>
<li><p>在 -1 至 1 之间归一化像素值。我们将使用 <code>Normalization</code> 层作为模型本身的一部分来进行此操作。</p>
</li>
</ul>
<p>一般而言，与采用已预处理数据的模型相反，开发以原始数据作为输入的模型是一种良好的做法。原因在于，如果模型需要预处理的数据，则每次导出模型以在其他地方（在网络浏览器、移动应用中）使用时，都需要重新实现完全相同的预处理流水线。这很快就会变得非常棘手。因此，在命中模型之前，我们应当尽可能少地进行预处理。</p>
<p>在这里，我们将在数据流水线中进行图像大小调整（因为深度神经网络只能处理连续的数据批次），并在创建模型时将其作为模型的一部分进行输入值缩放。</p>
<p>我们将图像的大小调整为 150x150：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">size = (<span class="number">150</span>, <span class="number">150</span>)</span><br><span class="line"></span><br><span class="line">train_ds = train_ds.<span class="built_in">map</span>(<span class="keyword">lambda</span> x, y: (tf.image.resize(x, size), y))</span><br><span class="line"><span class="comment"># map 的输入是一个函数名（函数地址）</span></span><br><span class="line"><span class="comment"># lambda 函数：输入 x 和 y，输出 resize 后的 x 和 y</span></span><br><span class="line">validation_ds = validation_ds.<span class="built_in">map</span>(<span class="keyword">lambda</span> x, y: (tf.image.resize(x, size), y))</span><br><span class="line">test_ds = test_ds.<span class="built_in">map</span>(<span class="keyword">lambda</span> x, y: (tf.image.resize(x, size), y))</span><br></pre></td></tr></table></figure>

<p>此外，我们对数据进行批处理并使用缓存和预提取来优化加载速度。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">batch_size = <span class="number">32</span></span><br><span class="line"></span><br><span class="line">train_ds = train_ds.cache().batch(batch_size).prefetch(buffer_size=<span class="number">10</span>)</span><br><span class="line">validation_ds = validation_ds.cache().batch(batch_size).prefetch(buffer_size=<span class="number">10</span>)</span><br><span class="line">test_ds = test_ds.cache().batch(batch_size).prefetch(buffer_size=<span class="number">10</span>)</span><br></pre></td></tr></table></figure>

<h3 id="使用随机数据扩充"><a href="#使用随机数据扩充" class="headerlink" title="使用随机数据扩充"></a>使用随机数据扩充</h3><p>当您没有较大的图像数据集时，通过将随机但现实的转换（例如随机水平翻转或小幅随机旋转）应用于训练图像来人为引入样本多样性是一种良好的做法。这有助于使模型暴露于训练数据的不同方面，同时减慢过拟合的速度。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> layers</span><br><span class="line"></span><br><span class="line">data_augmentation = keras.Sequential(</span><br><span class="line">    [</span><br><span class="line">        layers.experimental.preprocessing.RandomFlip(<span class="string">&quot;horizontal&quot;</span>),</span><br><span class="line">        layers.experimental.preprocessing.RandomRotation(<span class="number">0.1</span>),</span><br><span class="line">    ]</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<p>我们看一下经过各种随机转换后第一个批次的第一个图像是什么样：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> images, labels <span class="keyword">in</span> train_ds.take(<span class="number">1</span>):</span><br><span class="line">    plt.figure(figsize=(<span class="number">10</span>, <span class="number">10</span>))</span><br><span class="line">    first_image = images[<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">9</span>):</span><br><span class="line">        ax = plt.subplot(<span class="number">3</span>, <span class="number">3</span>, i + <span class="number">1</span>)</span><br><span class="line">        augmented_image = data_augmentation(</span><br><span class="line">            tf.expand_dims(first_image, <span class="number">0</span>), training=<span class="literal">True</span></span><br><span class="line">        )</span><br><span class="line">        plt.imshow(augmented_image[<span class="number">0</span>].numpy().astype(<span class="string">&quot;int32&quot;</span>))</span><br><span class="line">        plt.title(<span class="built_in">int</span>(labels[<span class="number">0</span>]))</span><br><span class="line">        plt.axis(<span class="string">&quot;off&quot;</span>)</span><br></pre></td></tr></table></figure>

<h3 id="构建模型"><a href="#构建模型" class="headerlink" title="构建模型"></a>构建模型</h3><p>现在，我们来构建一个遵循我们先前解释的蓝图的模型。</p>
<p>注意：</p>
<ul>
<li><p>我们添加 <code>Normalization</code> 层以将输入值（最初在 <code>[0, 255]</code> 范围内）缩放到 <code>[-1, 1]</code> 范围。</p>
</li>
<li><p>我们在分类层之前添加一个 <code>Dropout</code> 层，以进行正则化。</p>
</li>
<li><p>我们确保在调用基础模型时传递 <code>training=False</code>，使其在推断模式下运行，这样，即使在我们解冻基础模型以进行微调后，batchnorm 统计信息也不会更新。</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">base_model = keras.applications.Xception(</span><br><span class="line">    weights=<span class="string">&quot;imagenet&quot;</span>,  <span class="comment"># Load weights pre-trained on ImageNet.</span></span><br><span class="line">    input_shape=(<span class="number">150</span>, <span class="number">150</span>, <span class="number">3</span>),</span><br><span class="line">    include_top=<span class="literal">False</span>,</span><br><span class="line">)  <span class="comment"># Do not include the ImageNet classifier at the top.</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Freeze the base_model</span></span><br><span class="line">base_model.trainable = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Create new model on top</span></span><br><span class="line">inputs = keras.Input(shape=(<span class="number">150</span>, <span class="number">150</span>, <span class="number">3</span>))</span><br><span class="line">x = data_augmentation(inputs)  <span class="comment"># Apply random data augmentation</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Pre-trained Xception weights requires that input be normalized</span></span><br><span class="line"><span class="comment"># from (0, 255) to a range (-1., +1.), the normalization layer</span></span><br><span class="line"><span class="comment"># does the following, outputs = (inputs - mean) / sqrt(var)</span></span><br><span class="line">norm_layer = keras.layers.experimental.preprocessing.Normalization()</span><br><span class="line">mean = np.array([<span class="number">127.5</span>] * <span class="number">3</span>)</span><br><span class="line">var = mean ** <span class="number">2</span></span><br><span class="line"><span class="comment"># Scale inputs to [-1, +1]</span></span><br><span class="line">x = norm_layer(x)</span><br><span class="line">norm_layer.set_weights([mean, var])</span><br><span class="line"></span><br><span class="line"><span class="comment"># The base model contains batchnorm layers. We want to keep them in inference mode</span></span><br><span class="line"><span class="comment"># when we unfreeze the base model for fine-tuning, so we make sure that the</span></span><br><span class="line"><span class="comment"># base_model is running in inference mode here.</span></span><br><span class="line">x = base_model(x, training=<span class="literal">False</span>)</span><br><span class="line">x = keras.layers.GlobalAveragePooling2D()(x)</span><br><span class="line">x = keras.layers.Dropout(<span class="number">0.2</span>)(x)  <span class="comment"># Regularize with dropout</span></span><br><span class="line">outputs = keras.layers.Dense(<span class="number">1</span>)(x)</span><br><span class="line">model = keras.Model(inputs, outputs)</span><br><span class="line"></span><br><span class="line">model.summary()</span><br></pre></td></tr></table></figure>

<h3 id="训练顶层"><a href="#训练顶层" class="headerlink" title="训练顶层"></a>训练顶层</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">model.compile(</span><br><span class="line">    optimizer=keras.optimizers.Adam(),</span><br><span class="line">    loss=keras.losses.BinaryCrossentropy(from_logits=True),</span><br><span class="line">    metrics=[keras.metrics.BinaryAccuracy()],</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">epochs = 20</span><br><span class="line">model.fit(train_ds, epochs=epochs, validation_data=validation_ds)</span><br></pre></td></tr></table></figure>

<h3 id="对整个模型进行一轮微调"><a href="#对整个模型进行一轮微调" class="headerlink" title="对整个模型进行一轮微调"></a>对整个模型进行一轮微调</h3><p>最后，我们解冻基础模型，并以较低的学习率端到端地训练整个模型。</p>
<p>重要的是，尽管基础模型变得可训练，但在构建模型过程中，由于我们在调用该模型时传递了 <code>training=False</code>，因此它仍在推断模式下运行。这意味着内部的批次归一化层不会更新其批次统计信息。如果它们更新了这些统计信息，则会破坏该模型到目前为止所学习的表示。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Unfreeze the base_model. Note that it keeps running in inference mode</span></span><br><span class="line"><span class="comment"># since we passed `training=False` when calling it. This means that</span></span><br><span class="line"><span class="comment"># the batchnorm layers will not update their batch statistics.</span></span><br><span class="line"><span class="comment"># This prevents the batchnorm layers from undoing all the training</span></span><br><span class="line"><span class="comment"># we&#x27;ve done so far.</span></span><br><span class="line">base_model.trainable = <span class="literal">True</span></span><br><span class="line">model.summary()</span><br><span class="line"></span><br><span class="line">model.<span class="built_in">compile</span>(</span><br><span class="line">    optimizer=keras.optimizers.Adam(<span class="number">1e-5</span>),  <span class="comment"># Low learning rate</span></span><br><span class="line">    loss=keras.losses.BinaryCrossentropy(from_logits=<span class="literal">True</span>),</span><br><span class="line">    metrics=[keras.metrics.BinaryAccuracy()],</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">epochs = <span class="number">10</span></span><br><span class="line">model.fit(train_ds, epochs=epochs, validation_data=validation_ds)</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>DeepLearning</category>
      </categories>
      <tags>
        <tag>TransferLearning</tag>
        <tag>DeepLearning</tag>
        <tag>keras</tag>
      </tags>
  </entry>
</search>
